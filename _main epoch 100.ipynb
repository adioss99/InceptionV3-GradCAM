{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.applications import InceptionV3\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir  = 'augmented_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11864 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Bacterial Blight', 1: 'Blast', 2: 'Brown Spot', 3: 'Tungro'}\n"
     ]
    }
   ],
   "source": [
    "class_names = dataset.class_names\n",
    "class_names\n",
    "class_list = {}\n",
    "for i, classes in enumerate(class_names):\n",
    "    class_list[i] = classes\n",
    "\n",
    "print(class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Bacterial Blight: 3168 images\n",
      "Class Blast: 2880 images\n",
      "Class Brown Spot: 3200 images\n",
      "Class Tungro: 2616 images\n",
      "11864\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def distribution_class(dir):\n",
    "    class_dirs = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d))]\n",
    "    class_counts = Counter()\n",
    "\n",
    "    for class_dir in class_dirs:\n",
    "        class_path = os.path.join(dir, class_dir)\n",
    "        class_counts[class_dir] = len([name for name in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, name))])\n",
    "        \n",
    "    total = 0 \n",
    "    for class_name, count in class_counts.items():\n",
    "        total += count\n",
    "        print(f'Class {class_name}: {count} images')\n",
    "\n",
    "    print(total)\n",
    "\n",
    "    plt.figure(figsize=(5,2))\n",
    "    plt.bar(class_counts.keys(), class_counts.values())\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Number of images')\n",
    "    plt.title('Class Distribution')\n",
    "    plt.xticks(rotation=10)\n",
    "    plt.show()\n",
    "\n",
    "distribution_class(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 299\n",
    "width = 299\n",
    "batch_size = 32\n",
    "learning_rate = 0.0001\n",
    "epoch = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train, Validation, Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get image paths and labels\n",
    "def get_image_paths_and_labels(dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    class_names = os.listdir(dir)\n",
    "    for class_name in class_names:\n",
    "        class_dir = os.path.join(dir, class_name)\n",
    "        if os.path.isdir(class_dir):\n",
    "            for img_name in os.listdir(class_dir):\n",
    "                img_path = os.path.join(class_dir, img_name)\n",
    "                if os.path.isfile(img_path):\n",
    "                    image_paths.append(img_path)\n",
    "                    labels.append(class_name)\n",
    "    return image_paths, labels\n",
    "\n",
    "# Get all image paths and their corresponding labels\n",
    "image_paths, labels = get_image_paths_and_labels(dir)\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "train_paths, temp_paths, train_labels, temp_labels = train_test_split(image_paths, labels, test_size=0.4, stratify=labels)\n",
    "val_paths, test_paths, val_labels, test_labels = train_test_split(temp_paths, temp_labels, test_size=0.5, stratify=temp_labels)\n",
    "\n",
    "# Function to convert lists of paths and labels to a DataFrame\n",
    "def path_to_dataframe(image_paths, labels):\n",
    "    return pd.DataFrame(list(zip(image_paths, labels)), columns=['filename', 'class'])\n",
    "\n",
    "# Convert to DataFrames\n",
    "train_df = path_to_dataframe(train_paths, train_labels)\n",
    "val_df = path_to_dataframe(val_paths, val_labels)\n",
    "test_df = path_to_dataframe(test_paths, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7118 validated image filenames belonging to 4 classes.\n",
      "Found 2373 validated image filenames belonging to 4 classes.\n",
      "Found 2373 validated image filenames belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create data generators\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col='filename',\n",
    "    y_col='class',\n",
    "    target_size=(height, width),\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_dataframe(\n",
    "    val_df,\n",
    "    x_col='filename',\n",
    "    y_col='class',\n",
    "    target_size=(height, width),\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "test_generator = datagen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    x_col='filename',\n",
    "    y_col='class',\n",
    "    target_size=(height, width),\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(\n",
    "  include_top=False,\n",
    "  weights=\"imagenet\",\n",
    "  input_shape=(height, width, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(dense, dropout, summary = True):\n",
    "  base_model.trainable = False\n",
    "  \n",
    "  x = base_model.output\n",
    "\n",
    "  x = GlobalAveragePooling2D()(x)\n",
    "  if dense > 0:\n",
    "    x = Dense(dense, activation='relu')(x)\n",
    "  x = Dropout(dropout)(x)  \n",
    "  predictions = Dense(len(class_names), activation='softmax')(x)\n",
    "\n",
    "  model = Model(inputs=base_model.input, outputs=predictions, name= f'100_Dense_{dense}-DO_{dropout}')\n",
    "  \n",
    "  if summary:\n",
    "    model.summary()\n",
    "\n",
    "  model.compile(\n",
    "              optimizer=Adam(learning_rate=learning_rate), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy']\n",
    "            )\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = keras.callbacks.EarlyStopping(\n",
    "                        monitor='val_loss',\n",
    "                        patience=5,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, epoch=50):\n",
    "  history = model.fit(\n",
    "              train_generator,\n",
    "              verbose=1,\n",
    "              epochs=epoch,\n",
    "              validation_data = val_generator,\n",
    "            )\n",
    "  return history, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Dense_128-DO_0.5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 299, 299, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 149, 149, 32  864         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 149, 149, 32  96         ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 149, 149, 32  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 147, 147, 32  9216        ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 147, 147, 32  96         ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 147, 147, 32  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 147, 147, 64  18432       ['activation_1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 147, 147, 64  192        ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 147, 147, 64  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 73, 73, 64)   0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 73, 73, 80)   5120        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 73, 73, 80)  240         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 73, 73, 80)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 71, 71, 192)  138240      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 71, 71, 192)  576        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 71, 71, 192)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0          ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 35, 35, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 35, 35, 96)   55296       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 35, 35, 48)  144         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 35, 35, 96)  288         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 35, 35, 48)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 35, 35, 96)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 35, 35, 192)  0          ['max_pooling2d_1[0][0]']        \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 35, 35, 64)   76800       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 35, 35, 32)   6144        ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 35, 35, 96)  288         ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 35, 35, 32)  96          ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 35, 35, 256)  0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_7[0][0]',           \n",
      "                                                                  'activation_10[0][0]',          \n",
      "                                                                  'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 35, 35, 64)  192         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 35, 35, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 35, 35, 48)  144         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 35, 35, 96)  288         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 35, 35, 256)  0          ['mixed0[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 35, 35, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 35, 35, 64)  192         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 35, 35, 64)  192         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 35, 35, 96)  288         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 35, 35, 64)  192         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 35, 35, 288)  0           ['activation_12[0][0]',          \n",
      "                                                                  'activation_14[0][0]',          \n",
      "                                                                  'activation_17[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 35, 35, 64)  192         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 35, 35, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 35, 35, 48)  144         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 35, 35, 96)  288         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 35, 35, 288)  0          ['mixed1[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 35, 35, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 35, 35, 64)  192         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 35, 35, 64)  192         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 35, 35, 96)  288         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 35, 35, 64)  192         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 35, 35, 288)  0           ['activation_19[0][0]',          \n",
      "                                                                  'activation_21[0][0]',          \n",
      "                                                                  'activation_24[0][0]',          \n",
      "                                                                  'activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 35, 35, 64)  192         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 35, 35, 96)  288         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 17, 17, 384)  995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 17, 17, 96)   82944       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 17, 17, 384)  1152       ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 17, 17, 96)  288         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 17, 17, 384)  0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 17, 17, 96)   0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0          ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 17, 17, 768)  0           ['activation_26[0][0]',          \n",
      "                                                                  'activation_29[0][0]',          \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 17, 17, 128)  384        ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 17, 17, 128)  384        ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 17, 17, 128)  384        ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 17, 17, 128)  384        ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 17, 17, 128)  384        ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 17, 17, 128)  384        ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 17, 17, 768)  0          ['mixed3[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 17, 17, 192)  576        ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 17, 17, 192)  576        ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 17, 17, 192)  576        ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 17, 17, 192)  576        ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 17, 17, 768)  0           ['activation_30[0][0]',          \n",
      "                                                                  'activation_33[0][0]',          \n",
      "                                                                  'activation_38[0][0]',          \n",
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 17, 17, 160)  480        ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 17, 17, 160)  480        ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 17, 17, 160)  480        ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 17, 17, 160)  480        ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 17, 17, 160)  480        ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 17, 17, 160)  480        ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, 17, 17, 768)  0          ['mixed4[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 17, 17, 192)  576        ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 17, 17, 192)  576        ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 17, 17, 192)  576        ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 17, 17, 192)  576        ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 17, 17, 768)  0           ['activation_40[0][0]',          \n",
      "                                                                  'activation_43[0][0]',          \n",
      "                                                                  'activation_48[0][0]',          \n",
      "                                                                  'activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 17, 17, 160)  480        ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 17, 17, 160)  480        ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 17, 17, 160)  480        ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 17, 17, 160)  480        ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 17, 17, 160)  480        ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 17, 17, 160)  480        ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, 17, 17, 768)  0          ['mixed5[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_5[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 17, 17, 192)  576        ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 17, 17, 192)  576        ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 17, 17, 192)  576        ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 17, 17, 192)  576        ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 17, 17, 768)  0           ['activation_50[0][0]',          \n",
      "                                                                  'activation_53[0][0]',          \n",
      "                                                                  'activation_58[0][0]',          \n",
      "                                                                  'activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 17, 17, 192)  576        ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 17, 17, 192)  576        ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 17, 17, 192)  576        ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 17, 17, 192)  576        ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 17, 17, 192)  576        ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 17, 17, 192)  576        ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (AveragePo  (None, 17, 17, 768)  0          ['mixed6[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_6[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 17, 17, 192)  576        ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 17, 17, 192)  576        ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 17, 17, 192)  576        ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 17, 17, 192)  576        ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 17, 17, 768)  0           ['activation_60[0][0]',          \n",
      "                                                                  'activation_63[0][0]',          \n",
      "                                                                  'activation_68[0][0]',          \n",
      "                                                                  'activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 17, 17, 192)  576        ['conv2d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_72[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 17, 17, 192)  576        ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_73[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 17, 17, 192)  576        ['conv2d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 17, 17, 192)  576        ['conv2d_74[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 8, 8, 320)    552960      ['activation_70[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 8, 8, 192)    331776      ['activation_74[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 8, 8, 320)   960         ['conv2d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 8, 8, 192)   576         ['conv2d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)   0           ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 8, 8, 1280)   0           ['activation_71[0][0]',          \n",
      "                                                                  'activation_75[0][0]',          \n",
      "                                                                  'max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 8, 8, 448)    573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_80[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 8, 8, 384)    491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_80[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_7 (AveragePo  (None, 8, 8, 1280)  0           ['mixed8[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 8, 8, 320)    409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_78[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_79[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_82[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_83[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 8, 8, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 8, 8, 320)   960         ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 8, 8, 192)   576         ['conv2d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 8, 8, 768)    0           ['activation_78[0][0]',          \n",
      "                                                                  'activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 8, 8, 768)    0           ['activation_82[0][0]',          \n",
      "                                                                  'activation_83[0][0]']          \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, 8, 8, 2048)   0           ['activation_76[0][0]',          \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate[0][0]',            \n",
      "                                                                  'activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 8, 8, 448)    917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 8, 8, 384)    786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_89[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_86[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_8 (AveragePo  (None, 8, 8, 2048)  0           ['mixed9[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 8, 8, 320)    655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_88[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_91[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_92[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 8, 8, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 8, 8, 320)   960         ['conv2d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 8, 8, 192)   576         ['conv2d_93[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 8, 8, 768)    0           ['activation_87[0][0]',          \n",
      "                                                                  'activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 8, 8, 768)    0           ['activation_91[0][0]',          \n",
      "                                                                  'activation_92[0][0]']          \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 8, 8, 2048)   0           ['activation_85[0][0]',          \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_1[0][0]',          \n",
      "                                                                  'activation_93[0][0]']          \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2 (Gl  (None, 2048)        0           ['mixed10[0][0]']                \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 128)          262272      ['global_average_pooling2d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128)          0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 4)            516         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 22,065,572\n",
      "Trainable params: 262,788\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "build_0 = build_model(128, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "223/223 [==============================] - 97s 414ms/step - loss: 0.7231 - accuracy: 0.7194 - val_loss: 0.3748 - val_accuracy: 0.8850\n",
      "Epoch 2/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.3788 - accuracy: 0.8654 - val_loss: 0.2483 - val_accuracy: 0.9254\n",
      "Epoch 3/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.2804 - accuracy: 0.9050 - val_loss: 0.1801 - val_accuracy: 0.9482\n",
      "Epoch 4/100\n",
      "223/223 [==============================] - 55s 244ms/step - loss: 0.2255 - accuracy: 0.9255 - val_loss: 0.1462 - val_accuracy: 0.9650\n",
      "Epoch 5/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1821 - accuracy: 0.9451 - val_loss: 0.1258 - val_accuracy: 0.9642\n",
      "Epoch 6/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1518 - accuracy: 0.9536 - val_loss: 0.1009 - val_accuracy: 0.9751\n",
      "Epoch 7/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.1280 - accuracy: 0.9619 - val_loss: 0.0902 - val_accuracy: 0.9772\n",
      "Epoch 8/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.1129 - accuracy: 0.9668 - val_loss: 0.0784 - val_accuracy: 0.9810\n",
      "Epoch 9/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.1008 - accuracy: 0.9704 - val_loss: 0.0700 - val_accuracy: 0.9853\n",
      "Epoch 10/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0880 - accuracy: 0.9770 - val_loss: 0.0651 - val_accuracy: 0.9840\n",
      "Epoch 11/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0772 - accuracy: 0.9792 - val_loss: 0.0570 - val_accuracy: 0.9874\n",
      "Epoch 12/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0752 - accuracy: 0.9796 - val_loss: 0.0516 - val_accuracy: 0.9895\n",
      "Epoch 13/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0631 - accuracy: 0.9834 - val_loss: 0.0530 - val_accuracy: 0.9869\n",
      "Epoch 14/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0567 - accuracy: 0.9843 - val_loss: 0.0438 - val_accuracy: 0.9907\n",
      "Epoch 15/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.0542 - accuracy: 0.9883 - val_loss: 0.0426 - val_accuracy: 0.9912\n",
      "Epoch 16/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0458 - accuracy: 0.9892 - val_loss: 0.0382 - val_accuracy: 0.9912\n",
      "Epoch 17/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0429 - accuracy: 0.9900 - val_loss: 0.0357 - val_accuracy: 0.9920\n",
      "Epoch 18/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0383 - accuracy: 0.9921 - val_loss: 0.0338 - val_accuracy: 0.9933\n",
      "Epoch 19/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0369 - accuracy: 0.9920 - val_loss: 0.0321 - val_accuracy: 0.9924\n",
      "Epoch 20/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0327 - accuracy: 0.9938 - val_loss: 0.0301 - val_accuracy: 0.9928\n",
      "Epoch 21/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.0287 - accuracy: 0.9942 - val_loss: 0.0289 - val_accuracy: 0.9937\n",
      "Epoch 22/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.0259 - accuracy: 0.9963 - val_loss: 0.0290 - val_accuracy: 0.9933\n",
      "Epoch 23/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.0256 - accuracy: 0.9945 - val_loss: 0.0283 - val_accuracy: 0.9933\n",
      "Epoch 24/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0235 - accuracy: 0.9963 - val_loss: 0.0265 - val_accuracy: 0.9920\n",
      "Epoch 25/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0230 - accuracy: 0.9955 - val_loss: 0.0252 - val_accuracy: 0.9941\n",
      "Epoch 26/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0192 - accuracy: 0.9975 - val_loss: 0.0263 - val_accuracy: 0.9928\n",
      "Epoch 27/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0183 - accuracy: 0.9963 - val_loss: 0.0281 - val_accuracy: 0.9903\n",
      "Epoch 28/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0171 - accuracy: 0.9975 - val_loss: 0.0222 - val_accuracy: 0.9945\n",
      "Epoch 29/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.0167 - accuracy: 0.9972 - val_loss: 0.0227 - val_accuracy: 0.9937\n",
      "Epoch 30/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0150 - accuracy: 0.9978 - val_loss: 0.0210 - val_accuracy: 0.9954\n",
      "Epoch 31/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0136 - accuracy: 0.9978 - val_loss: 0.0215 - val_accuracy: 0.9937\n",
      "Epoch 32/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0133 - accuracy: 0.9983 - val_loss: 0.0195 - val_accuracy: 0.9941\n",
      "Epoch 33/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0113 - accuracy: 0.9986 - val_loss: 0.0185 - val_accuracy: 0.9954\n",
      "Epoch 34/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0123 - accuracy: 0.9978 - val_loss: 0.0213 - val_accuracy: 0.9945\n",
      "Epoch 35/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0114 - accuracy: 0.9982 - val_loss: 0.0217 - val_accuracy: 0.9941\n",
      "Epoch 36/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.0100 - accuracy: 0.9992 - val_loss: 0.0206 - val_accuracy: 0.9945\n",
      "Epoch 37/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0100 - accuracy: 0.9987 - val_loss: 0.0191 - val_accuracy: 0.9945\n",
      "Epoch 38/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0090 - accuracy: 0.9993 - val_loss: 0.0183 - val_accuracy: 0.9941\n",
      "Epoch 39/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0071 - accuracy: 0.9990 - val_loss: 0.0234 - val_accuracy: 0.9924\n",
      "Epoch 40/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0071 - accuracy: 0.9993 - val_loss: 0.0181 - val_accuracy: 0.9954\n",
      "Epoch 41/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0094 - accuracy: 0.9983 - val_loss: 0.0174 - val_accuracy: 0.9945\n",
      "Epoch 42/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0080 - accuracy: 0.9992 - val_loss: 0.0177 - val_accuracy: 0.9941\n",
      "Epoch 43/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 0.9954\n",
      "Epoch 44/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.0061 - accuracy: 0.9993 - val_loss: 0.0172 - val_accuracy: 0.9941\n",
      "Epoch 45/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0052 - accuracy: 0.9997 - val_loss: 0.0174 - val_accuracy: 0.9958\n",
      "Epoch 46/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0065 - accuracy: 0.9987 - val_loss: 0.0179 - val_accuracy: 0.9954\n",
      "Epoch 47/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0052 - accuracy: 0.9997 - val_loss: 0.0172 - val_accuracy: 0.9945\n",
      "Epoch 48/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0044 - accuracy: 0.9997 - val_loss: 0.0163 - val_accuracy: 0.9945\n",
      "Epoch 49/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.0050 - accuracy: 0.9997 - val_loss: 0.0177 - val_accuracy: 0.9945\n",
      "Epoch 50/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0061 - accuracy: 0.9993 - val_loss: 0.0180 - val_accuracy: 0.9949\n",
      "Epoch 51/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0066 - accuracy: 0.9992 - val_loss: 0.0174 - val_accuracy: 0.9954\n",
      "Epoch 52/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0044 - accuracy: 0.9999 - val_loss: 0.0186 - val_accuracy: 0.9933\n",
      "Epoch 53/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0040 - accuracy: 0.9997 - val_loss: 0.0179 - val_accuracy: 0.9933\n",
      "Epoch 54/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.0187 - val_accuracy: 0.9933\n",
      "Epoch 55/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0038 - accuracy: 0.9999 - val_loss: 0.0179 - val_accuracy: 0.9941\n",
      "Epoch 56/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0039 - accuracy: 0.9996 - val_loss: 0.0194 - val_accuracy: 0.9937\n",
      "Epoch 57/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0034 - accuracy: 0.9999 - val_loss: 0.0180 - val_accuracy: 0.9937\n",
      "Epoch 58/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 0.0149 - val_accuracy: 0.9954\n",
      "Epoch 59/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0038 - accuracy: 0.9996 - val_loss: 0.0162 - val_accuracy: 0.9941\n",
      "Epoch 60/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 0.0171 - val_accuracy: 0.9949\n",
      "Epoch 61/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.0165 - val_accuracy: 0.9954\n",
      "Epoch 62/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0033 - accuracy: 0.9996 - val_loss: 0.0172 - val_accuracy: 0.9945\n",
      "Epoch 63/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0224 - val_accuracy: 0.9928\n",
      "Epoch 64/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.0158 - val_accuracy: 0.9949\n",
      "Epoch 65/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.0166 - val_accuracy: 0.9949\n",
      "Epoch 66/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0032 - accuracy: 0.9997 - val_loss: 0.0159 - val_accuracy: 0.9962\n",
      "Epoch 67/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.0160 - val_accuracy: 0.9962\n",
      "Epoch 68/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9962\n",
      "Epoch 69/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0163 - val_accuracy: 0.9941\n",
      "Epoch 70/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.0156 - val_accuracy: 0.9966\n",
      "Epoch 71/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 0.9954\n",
      "Epoch 72/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.0160 - val_accuracy: 0.9954\n",
      "Epoch 73/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.0164 - val_accuracy: 0.9949\n",
      "Epoch 74/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.0165 - val_accuracy: 0.9937\n",
      "Epoch 75/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 0.9945\n",
      "Epoch 76/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9958\n",
      "Epoch 77/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9958\n",
      "Epoch 78/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 0.9949\n",
      "Epoch 79/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9954\n",
      "Epoch 80/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.0175 - val_accuracy: 0.9949\n",
      "Epoch 81/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.0174 - val_accuracy: 0.9954\n",
      "Epoch 82/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.0177 - val_accuracy: 0.9945\n",
      "Epoch 83/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0159 - val_accuracy: 0.9949\n",
      "Epoch 84/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0141 - val_accuracy: 0.9958\n",
      "Epoch 85/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0162 - val_accuracy: 0.9945\n",
      "Epoch 86/100\n",
      "223/223 [==============================] - 55s 249ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9945\n",
      "Epoch 87/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.0172 - val_accuracy: 0.9958\n",
      "Epoch 88/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0148 - val_accuracy: 0.9966\n",
      "Epoch 89/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 0.9954\n",
      "Epoch 90/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0151 - val_accuracy: 0.9954\n",
      "Epoch 91/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 0.9954\n",
      "Epoch 92/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0151 - val_accuracy: 0.9966\n",
      "Epoch 93/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.0127 - val_accuracy: 0.9962\n",
      "Epoch 94/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0045 - accuracy: 0.9983 - val_loss: 0.0154 - val_accuracy: 0.9945\n",
      "Epoch 95/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9958\n",
      "Epoch 96/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0147 - val_accuracy: 0.9966\n",
      "Epoch 97/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0163 - val_accuracy: 0.9958\n",
      "Epoch 98/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0152 - val_accuracy: 0.9971\n",
      "Epoch 99/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.0152 - val_accuracy: 0.9962\n",
      "Epoch 100/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0174 - val_accuracy: 0.9962\n"
     ]
    }
   ],
   "source": [
    "history_0, model_0 = fit_model(build_0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Dense_64-DO_0.5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 299, 299, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 149, 149, 32  864         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 149, 149, 32  96         ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 149, 149, 32  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 147, 147, 32  9216        ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 147, 147, 32  96         ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 147, 147, 32  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 147, 147, 64  18432       ['activation_1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 147, 147, 64  192        ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 147, 147, 64  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 73, 73, 64)   0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 73, 73, 80)   5120        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 73, 73, 80)  240         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 73, 73, 80)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 71, 71, 192)  138240      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 71, 71, 192)  576        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 71, 71, 192)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0          ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 35, 35, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 35, 35, 96)   55296       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 35, 35, 48)  144         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 35, 35, 96)  288         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 35, 35, 48)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 35, 35, 96)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 35, 35, 192)  0          ['max_pooling2d_1[0][0]']        \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 35, 35, 64)   76800       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 35, 35, 32)   6144        ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 35, 35, 96)  288         ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 35, 35, 32)  96          ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 35, 35, 256)  0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_7[0][0]',           \n",
      "                                                                  'activation_10[0][0]',          \n",
      "                                                                  'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 35, 35, 64)  192         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 35, 35, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 35, 35, 48)  144         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 35, 35, 96)  288         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 35, 35, 256)  0          ['mixed0[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 35, 35, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 35, 35, 64)  192         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 35, 35, 64)  192         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 35, 35, 96)  288         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 35, 35, 64)  192         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 35, 35, 288)  0           ['activation_12[0][0]',          \n",
      "                                                                  'activation_14[0][0]',          \n",
      "                                                                  'activation_17[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 35, 35, 64)  192         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 35, 35, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 35, 35, 48)  144         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 35, 35, 96)  288         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 35, 35, 288)  0          ['mixed1[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 35, 35, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 35, 35, 64)  192         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 35, 35, 64)  192         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 35, 35, 96)  288         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 35, 35, 64)  192         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 35, 35, 288)  0           ['activation_19[0][0]',          \n",
      "                                                                  'activation_21[0][0]',          \n",
      "                                                                  'activation_24[0][0]',          \n",
      "                                                                  'activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 35, 35, 64)  192         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 35, 35, 96)  288         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 17, 17, 384)  995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 17, 17, 96)   82944       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 17, 17, 384)  1152       ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 17, 17, 96)  288         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 17, 17, 384)  0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 17, 17, 96)   0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0          ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 17, 17, 768)  0           ['activation_26[0][0]',          \n",
      "                                                                  'activation_29[0][0]',          \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 17, 17, 128)  384        ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 17, 17, 128)  384        ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 17, 17, 128)  384        ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 17, 17, 128)  384        ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 17, 17, 128)  384        ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 17, 17, 128)  384        ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 17, 17, 768)  0          ['mixed3[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 17, 17, 192)  576        ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 17, 17, 192)  576        ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 17, 17, 192)  576        ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 17, 17, 192)  576        ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 17, 17, 768)  0           ['activation_30[0][0]',          \n",
      "                                                                  'activation_33[0][0]',          \n",
      "                                                                  'activation_38[0][0]',          \n",
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 17, 17, 160)  480        ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 17, 17, 160)  480        ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 17, 17, 160)  480        ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 17, 17, 160)  480        ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 17, 17, 160)  480        ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 17, 17, 160)  480        ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, 17, 17, 768)  0          ['mixed4[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 17, 17, 192)  576        ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 17, 17, 192)  576        ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 17, 17, 192)  576        ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 17, 17, 192)  576        ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 17, 17, 768)  0           ['activation_40[0][0]',          \n",
      "                                                                  'activation_43[0][0]',          \n",
      "                                                                  'activation_48[0][0]',          \n",
      "                                                                  'activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 17, 17, 160)  480        ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 17, 17, 160)  480        ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 17, 17, 160)  480        ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 17, 17, 160)  480        ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 17, 17, 160)  480        ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 17, 17, 160)  480        ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, 17, 17, 768)  0          ['mixed5[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_5[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 17, 17, 192)  576        ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 17, 17, 192)  576        ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 17, 17, 192)  576        ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 17, 17, 192)  576        ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 17, 17, 768)  0           ['activation_50[0][0]',          \n",
      "                                                                  'activation_53[0][0]',          \n",
      "                                                                  'activation_58[0][0]',          \n",
      "                                                                  'activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 17, 17, 192)  576        ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 17, 17, 192)  576        ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 17, 17, 192)  576        ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 17, 17, 192)  576        ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 17, 17, 192)  576        ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 17, 17, 192)  576        ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (AveragePo  (None, 17, 17, 768)  0          ['mixed6[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_6[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 17, 17, 192)  576        ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 17, 17, 192)  576        ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 17, 17, 192)  576        ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 17, 17, 192)  576        ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 17, 17, 768)  0           ['activation_60[0][0]',          \n",
      "                                                                  'activation_63[0][0]',          \n",
      "                                                                  'activation_68[0][0]',          \n",
      "                                                                  'activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 17, 17, 192)  576        ['conv2d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_72[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 17, 17, 192)  576        ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_73[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 17, 17, 192)  576        ['conv2d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 17, 17, 192)  576        ['conv2d_74[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 8, 8, 320)    552960      ['activation_70[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 8, 8, 192)    331776      ['activation_74[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 8, 8, 320)   960         ['conv2d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 8, 8, 192)   576         ['conv2d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)   0           ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 8, 8, 1280)   0           ['activation_71[0][0]',          \n",
      "                                                                  'activation_75[0][0]',          \n",
      "                                                                  'max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 8, 8, 448)    573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_80[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 8, 8, 384)    491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_80[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_7 (AveragePo  (None, 8, 8, 1280)  0           ['mixed8[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 8, 8, 320)    409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_78[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_79[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_82[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_83[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 8, 8, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 8, 8, 320)   960         ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 8, 8, 192)   576         ['conv2d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 8, 8, 768)    0           ['activation_78[0][0]',          \n",
      "                                                                  'activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 8, 8, 768)    0           ['activation_82[0][0]',          \n",
      "                                                                  'activation_83[0][0]']          \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, 8, 8, 2048)   0           ['activation_76[0][0]',          \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate[0][0]',            \n",
      "                                                                  'activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 8, 8, 448)    917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 8, 8, 384)    786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_89[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_86[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_8 (AveragePo  (None, 8, 8, 2048)  0           ['mixed9[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 8, 8, 320)    655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_88[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_91[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_92[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 8, 8, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 8, 8, 320)   960         ['conv2d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 8, 8, 192)   576         ['conv2d_93[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 8, 8, 768)    0           ['activation_87[0][0]',          \n",
      "                                                                  'activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 8, 8, 768)    0           ['activation_91[0][0]',          \n",
      "                                                                  'activation_92[0][0]']          \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 8, 8, 2048)   0           ['activation_85[0][0]',          \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_1[0][0]',          \n",
      "                                                                  'activation_93[0][0]']          \n",
      "                                                                                                  \n",
      " global_average_pooling2d_3 (Gl  (None, 2048)        0           ['mixed10[0][0]']                \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 64)           131136      ['global_average_pooling2d_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 64)           0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 4)            260         ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,934,180\n",
      "Trainable params: 131,396\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = build_model(64, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.4041 - accuracy: 0.8539 - val_loss: 0.2736 - val_accuracy: 0.9094\n",
      "Epoch 2/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.3182 - accuracy: 0.8929 - val_loss: 0.2203 - val_accuracy: 0.9334\n",
      "Epoch 3/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.2755 - accuracy: 0.9070 - val_loss: 0.1786 - val_accuracy: 0.9503\n",
      "Epoch 4/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.2354 - accuracy: 0.9234 - val_loss: 0.1510 - val_accuracy: 0.9600\n",
      "Epoch 5/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.2062 - accuracy: 0.9348 - val_loss: 0.1336 - val_accuracy: 0.9659\n",
      "Epoch 6/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.1809 - accuracy: 0.9421 - val_loss: 0.1216 - val_accuracy: 0.9654\n",
      "Epoch 7/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1594 - accuracy: 0.9513 - val_loss: 0.1060 - val_accuracy: 0.9713\n",
      "Epoch 8/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1467 - accuracy: 0.9556 - val_loss: 0.0949 - val_accuracy: 0.9756\n",
      "Epoch 9/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.1352 - accuracy: 0.9612 - val_loss: 0.0939 - val_accuracy: 0.9730\n",
      "Epoch 10/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.1250 - accuracy: 0.9638 - val_loss: 0.0843 - val_accuracy: 0.9802\n",
      "Epoch 11/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.1090 - accuracy: 0.9704 - val_loss: 0.0728 - val_accuracy: 0.9844\n",
      "Epoch 12/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.1023 - accuracy: 0.9730 - val_loss: 0.0708 - val_accuracy: 0.9831\n",
      "Epoch 13/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.0924 - accuracy: 0.9751 - val_loss: 0.0630 - val_accuracy: 0.9844\n",
      "Epoch 14/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0855 - accuracy: 0.9770 - val_loss: 0.0576 - val_accuracy: 0.9861\n",
      "Epoch 15/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0833 - accuracy: 0.9793 - val_loss: 0.0560 - val_accuracy: 0.9869\n",
      "Epoch 16/100\n",
      "223/223 [==============================] - 61s 273ms/step - loss: 0.0729 - accuracy: 0.9812 - val_loss: 0.0513 - val_accuracy: 0.9886\n",
      "Epoch 17/100\n",
      "223/223 [==============================] - 70s 313ms/step - loss: 0.0680 - accuracy: 0.9817 - val_loss: 0.0495 - val_accuracy: 0.9890\n",
      "Epoch 18/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0636 - accuracy: 0.9838 - val_loss: 0.0467 - val_accuracy: 0.9869\n",
      "Epoch 19/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0579 - accuracy: 0.9855 - val_loss: 0.0466 - val_accuracy: 0.9840\n",
      "Epoch 20/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0562 - accuracy: 0.9855 - val_loss: 0.0432 - val_accuracy: 0.9865\n",
      "Epoch 21/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0506 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9899\n",
      "Epoch 22/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0495 - accuracy: 0.9886 - val_loss: 0.0387 - val_accuracy: 0.9895\n",
      "Epoch 23/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0484 - accuracy: 0.9895 - val_loss: 0.0405 - val_accuracy: 0.9890\n",
      "Epoch 24/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0446 - accuracy: 0.9897 - val_loss: 0.0368 - val_accuracy: 0.9886\n",
      "Epoch 25/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0402 - accuracy: 0.9900 - val_loss: 0.0340 - val_accuracy: 0.9890\n",
      "Epoch 26/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0380 - accuracy: 0.9914 - val_loss: 0.0324 - val_accuracy: 0.9907\n",
      "Epoch 27/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.0370 - accuracy: 0.9921 - val_loss: 0.0307 - val_accuracy: 0.9920\n",
      "Epoch 28/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0356 - accuracy: 0.9928 - val_loss: 0.0303 - val_accuracy: 0.9916\n",
      "Epoch 29/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0316 - accuracy: 0.9927 - val_loss: 0.0307 - val_accuracy: 0.9903\n",
      "Epoch 30/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0320 - accuracy: 0.9919 - val_loss: 0.0303 - val_accuracy: 0.9912\n",
      "Epoch 31/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0302 - accuracy: 0.9931 - val_loss: 0.0323 - val_accuracy: 0.9912\n",
      "Epoch 32/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0296 - accuracy: 0.9931 - val_loss: 0.0282 - val_accuracy: 0.9912\n",
      "Epoch 33/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0272 - accuracy: 0.9937 - val_loss: 0.0291 - val_accuracy: 0.9920\n",
      "Epoch 34/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.0264 - accuracy: 0.9944 - val_loss: 0.0266 - val_accuracy: 0.9912\n",
      "Epoch 35/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0256 - accuracy: 0.9940 - val_loss: 0.0280 - val_accuracy: 0.9912\n",
      "Epoch 36/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0232 - accuracy: 0.9949 - val_loss: 0.0302 - val_accuracy: 0.9903\n",
      "Epoch 37/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0219 - accuracy: 0.9954 - val_loss: 0.0263 - val_accuracy: 0.9920\n",
      "Epoch 38/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0193 - accuracy: 0.9972 - val_loss: 0.0299 - val_accuracy: 0.9890\n",
      "Epoch 39/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0217 - accuracy: 0.9955 - val_loss: 0.0246 - val_accuracy: 0.9924\n",
      "Epoch 40/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0185 - accuracy: 0.9966 - val_loss: 0.0243 - val_accuracy: 0.9928\n",
      "Epoch 41/100\n",
      "223/223 [==============================] - 55s 249ms/step - loss: 0.0177 - accuracy: 0.9965 - val_loss: 0.0252 - val_accuracy: 0.9933\n",
      "Epoch 42/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.0167 - accuracy: 0.9969 - val_loss: 0.0247 - val_accuracy: 0.9928\n",
      "Epoch 43/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.0155 - accuracy: 0.9969 - val_loss: 0.0240 - val_accuracy: 0.9924\n",
      "Epoch 44/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0145 - accuracy: 0.9968 - val_loss: 0.0251 - val_accuracy: 0.9912\n",
      "Epoch 45/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0138 - accuracy: 0.9983 - val_loss: 0.0254 - val_accuracy: 0.9916\n",
      "Epoch 46/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0147 - accuracy: 0.9976 - val_loss: 0.0239 - val_accuracy: 0.9920\n",
      "Epoch 47/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0151 - accuracy: 0.9970 - val_loss: 0.0250 - val_accuracy: 0.9928\n",
      "Epoch 48/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.0125 - accuracy: 0.9983 - val_loss: 0.0240 - val_accuracy: 0.9920\n",
      "Epoch 49/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0128 - accuracy: 0.9980 - val_loss: 0.0226 - val_accuracy: 0.9907\n",
      "Epoch 50/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0135 - accuracy: 0.9973 - val_loss: 0.0221 - val_accuracy: 0.9928\n",
      "Epoch 51/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0133 - accuracy: 0.9972 - val_loss: 0.0265 - val_accuracy: 0.9903\n",
      "Epoch 52/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0125 - accuracy: 0.9976 - val_loss: 0.0245 - val_accuracy: 0.9912\n",
      "Epoch 53/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0113 - accuracy: 0.9979 - val_loss: 0.0216 - val_accuracy: 0.9928\n",
      "Epoch 54/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0103 - accuracy: 0.9986 - val_loss: 0.0218 - val_accuracy: 0.9928\n",
      "Epoch 55/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.0112 - accuracy: 0.9978 - val_loss: 0.0213 - val_accuracy: 0.9937\n",
      "Epoch 56/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.0099 - accuracy: 0.9986 - val_loss: 0.0213 - val_accuracy: 0.9928\n",
      "Epoch 57/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.0079 - accuracy: 0.9987 - val_loss: 0.0250 - val_accuracy: 0.9928\n",
      "Epoch 58/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.0095 - accuracy: 0.9986 - val_loss: 0.0196 - val_accuracy: 0.9945\n",
      "Epoch 59/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.0087 - accuracy: 0.9987 - val_loss: 0.0207 - val_accuracy: 0.9937\n",
      "Epoch 60/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.0090 - accuracy: 0.9985 - val_loss: 0.0226 - val_accuracy: 0.9920\n",
      "Epoch 61/100\n",
      "223/223 [==============================] - 56s 252ms/step - loss: 0.0092 - accuracy: 0.9985 - val_loss: 0.0243 - val_accuracy: 0.9928\n",
      "Epoch 62/100\n",
      "223/223 [==============================] - 56s 249ms/step - loss: 0.0084 - accuracy: 0.9993 - val_loss: 0.0210 - val_accuracy: 0.9937\n",
      "Epoch 63/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0093 - accuracy: 0.9973 - val_loss: 0.0217 - val_accuracy: 0.9933\n",
      "Epoch 64/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0072 - accuracy: 0.9986 - val_loss: 0.0213 - val_accuracy: 0.9937\n",
      "Epoch 65/100\n",
      "223/223 [==============================] - 55s 249ms/step - loss: 0.0079 - accuracy: 0.9987 - val_loss: 0.0217 - val_accuracy: 0.9928\n",
      "Epoch 66/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0084 - accuracy: 0.9986 - val_loss: 0.0203 - val_accuracy: 0.9941\n",
      "Epoch 67/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.0065 - accuracy: 0.9990 - val_loss: 0.0232 - val_accuracy: 0.9928\n",
      "Epoch 68/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.0052 - accuracy: 0.9997 - val_loss: 0.0208 - val_accuracy: 0.9937\n",
      "Epoch 69/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0065 - accuracy: 0.9992 - val_loss: 0.0235 - val_accuracy: 0.9933\n",
      "Epoch 70/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0076 - accuracy: 0.9990 - val_loss: 0.0232 - val_accuracy: 0.9920\n",
      "Epoch 71/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0063 - accuracy: 0.9992 - val_loss: 0.0230 - val_accuracy: 0.9924\n",
      "Epoch 72/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.0062 - accuracy: 0.9993 - val_loss: 0.0193 - val_accuracy: 0.9941\n",
      "Epoch 73/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0054 - accuracy: 0.9993 - val_loss: 0.0215 - val_accuracy: 0.9933\n",
      "Epoch 74/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.0062 - accuracy: 0.9993 - val_loss: 0.0227 - val_accuracy: 0.9941\n",
      "Epoch 75/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.0050 - accuracy: 0.9997 - val_loss: 0.0215 - val_accuracy: 0.9924\n",
      "Epoch 76/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0061 - accuracy: 0.9990 - val_loss: 0.0214 - val_accuracy: 0.9937\n",
      "Epoch 77/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0067 - accuracy: 0.9985 - val_loss: 0.0218 - val_accuracy: 0.9937\n",
      "Epoch 78/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0052 - accuracy: 0.9994 - val_loss: 0.0198 - val_accuracy: 0.9933\n",
      "Epoch 79/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.0212 - val_accuracy: 0.9933\n",
      "Epoch 80/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0043 - accuracy: 0.9997 - val_loss: 0.0201 - val_accuracy: 0.9937\n",
      "Epoch 81/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0039 - accuracy: 0.9996 - val_loss: 0.0201 - val_accuracy: 0.9954\n",
      "Epoch 82/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.0214 - val_accuracy: 0.9928\n",
      "Epoch 83/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0052 - accuracy: 0.9994 - val_loss: 0.0266 - val_accuracy: 0.9907\n",
      "Epoch 84/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.0201 - val_accuracy: 0.9954\n",
      "Epoch 85/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.0203 - val_accuracy: 0.9941\n",
      "Epoch 86/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.0222 - val_accuracy: 0.9928\n",
      "Epoch 87/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0034 - accuracy: 0.9997 - val_loss: 0.0189 - val_accuracy: 0.9945\n",
      "Epoch 88/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.0206 - val_accuracy: 0.9949\n",
      "Epoch 89/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.0210 - val_accuracy: 0.9941\n",
      "Epoch 90/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.0204 - val_accuracy: 0.9928\n",
      "Epoch 91/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0221 - val_accuracy: 0.9954\n",
      "Epoch 92/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0034 - accuracy: 0.9999 - val_loss: 0.0220 - val_accuracy: 0.9941\n",
      "Epoch 93/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0225 - val_accuracy: 0.9933\n",
      "Epoch 94/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0033 - accuracy: 0.9996 - val_loss: 0.0222 - val_accuracy: 0.9937\n",
      "Epoch 95/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.0213 - val_accuracy: 0.9945\n",
      "Epoch 96/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.0184 - val_accuracy: 0.9937\n",
      "Epoch 97/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0042 - accuracy: 0.9999 - val_loss: 0.0217 - val_accuracy: 0.9928\n",
      "Epoch 98/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0038 - accuracy: 0.9996 - val_loss: 0.0212 - val_accuracy: 0.9941\n",
      "Epoch 99/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.0216 - val_accuracy: 0.9937\n",
      "Epoch 100/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 0.0213 - val_accuracy: 0.9928\n"
     ]
    }
   ],
   "source": [
    "history_1, model_1 = fit_model(model_1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Dense_0-DO_0.5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 299, 299, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 149, 149, 32  864         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 149, 149, 32  96         ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 149, 149, 32  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 147, 147, 32  9216        ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 147, 147, 32  96         ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 147, 147, 32  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 147, 147, 64  18432       ['activation_1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 147, 147, 64  192        ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 147, 147, 64  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 73, 73, 64)   0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 73, 73, 80)   5120        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 73, 73, 80)  240         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 73, 73, 80)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 71, 71, 192)  138240      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 71, 71, 192)  576        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 71, 71, 192)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0          ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 35, 35, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 35, 35, 96)   55296       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 35, 35, 48)  144         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 35, 35, 96)  288         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 35, 35, 48)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 35, 35, 96)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 35, 35, 192)  0          ['max_pooling2d_1[0][0]']        \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 35, 35, 64)   76800       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 35, 35, 32)   6144        ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 35, 35, 96)  288         ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 35, 35, 32)  96          ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 35, 35, 256)  0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_7[0][0]',           \n",
      "                                                                  'activation_10[0][0]',          \n",
      "                                                                  'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 35, 35, 64)  192         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 35, 35, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 35, 35, 48)  144         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 35, 35, 96)  288         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 35, 35, 256)  0          ['mixed0[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 35, 35, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 35, 35, 64)  192         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 35, 35, 64)  192         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 35, 35, 96)  288         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 35, 35, 64)  192         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 35, 35, 288)  0           ['activation_12[0][0]',          \n",
      "                                                                  'activation_14[0][0]',          \n",
      "                                                                  'activation_17[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 35, 35, 64)  192         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 35, 35, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 35, 35, 48)  144         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 35, 35, 96)  288         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 35, 35, 288)  0          ['mixed1[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 35, 35, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 35, 35, 64)  192         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 35, 35, 64)  192         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 35, 35, 96)  288         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 35, 35, 64)  192         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 35, 35, 288)  0           ['activation_19[0][0]',          \n",
      "                                                                  'activation_21[0][0]',          \n",
      "                                                                  'activation_24[0][0]',          \n",
      "                                                                  'activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 35, 35, 64)  192         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 35, 35, 96)  288         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 17, 17, 384)  995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 17, 17, 96)   82944       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 17, 17, 384)  1152       ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 17, 17, 96)  288         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 17, 17, 384)  0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 17, 17, 96)   0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0          ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 17, 17, 768)  0           ['activation_26[0][0]',          \n",
      "                                                                  'activation_29[0][0]',          \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 17, 17, 128)  384        ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 17, 17, 128)  384        ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 17, 17, 128)  384        ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 17, 17, 128)  384        ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 17, 17, 128)  384        ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 17, 17, 128)  384        ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 17, 17, 768)  0          ['mixed3[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 17, 17, 192)  576        ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 17, 17, 192)  576        ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 17, 17, 192)  576        ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 17, 17, 192)  576        ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 17, 17, 768)  0           ['activation_30[0][0]',          \n",
      "                                                                  'activation_33[0][0]',          \n",
      "                                                                  'activation_38[0][0]',          \n",
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 17, 17, 160)  480        ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 17, 17, 160)  480        ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 17, 17, 160)  480        ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 17, 17, 160)  480        ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 17, 17, 160)  480        ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 17, 17, 160)  480        ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, 17, 17, 768)  0          ['mixed4[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 17, 17, 192)  576        ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 17, 17, 192)  576        ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 17, 17, 192)  576        ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 17, 17, 192)  576        ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 17, 17, 768)  0           ['activation_40[0][0]',          \n",
      "                                                                  'activation_43[0][0]',          \n",
      "                                                                  'activation_48[0][0]',          \n",
      "                                                                  'activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 17, 17, 160)  480        ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 17, 17, 160)  480        ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 17, 17, 160)  480        ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 17, 17, 160)  480        ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 17, 17, 160)  480        ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 17, 17, 160)  480        ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, 17, 17, 768)  0          ['mixed5[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_5[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 17, 17, 192)  576        ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 17, 17, 192)  576        ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 17, 17, 192)  576        ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 17, 17, 192)  576        ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 17, 17, 768)  0           ['activation_50[0][0]',          \n",
      "                                                                  'activation_53[0][0]',          \n",
      "                                                                  'activation_58[0][0]',          \n",
      "                                                                  'activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 17, 17, 192)  576        ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 17, 17, 192)  576        ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 17, 17, 192)  576        ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 17, 17, 192)  576        ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 17, 17, 192)  576        ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 17, 17, 192)  576        ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (AveragePo  (None, 17, 17, 768)  0          ['mixed6[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_6[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 17, 17, 192)  576        ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 17, 17, 192)  576        ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 17, 17, 192)  576        ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 17, 17, 192)  576        ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 17, 17, 768)  0           ['activation_60[0][0]',          \n",
      "                                                                  'activation_63[0][0]',          \n",
      "                                                                  'activation_68[0][0]',          \n",
      "                                                                  'activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 17, 17, 192)  576        ['conv2d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_72[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 17, 17, 192)  576        ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_73[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 17, 17, 192)  576        ['conv2d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 17, 17, 192)  576        ['conv2d_74[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 8, 8, 320)    552960      ['activation_70[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 8, 8, 192)    331776      ['activation_74[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 8, 8, 320)   960         ['conv2d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 8, 8, 192)   576         ['conv2d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)   0           ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 8, 8, 1280)   0           ['activation_71[0][0]',          \n",
      "                                                                  'activation_75[0][0]',          \n",
      "                                                                  'max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 8, 8, 448)    573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_80[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 8, 8, 384)    491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_80[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_7 (AveragePo  (None, 8, 8, 1280)  0           ['mixed8[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 8, 8, 320)    409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_78[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_79[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_82[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_83[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 8, 8, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 8, 8, 320)   960         ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 8, 8, 192)   576         ['conv2d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 8, 8, 768)    0           ['activation_78[0][0]',          \n",
      "                                                                  'activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 8, 8, 768)    0           ['activation_82[0][0]',          \n",
      "                                                                  'activation_83[0][0]']          \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, 8, 8, 2048)   0           ['activation_76[0][0]',          \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate[0][0]',            \n",
      "                                                                  'activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 8, 8, 448)    917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 8, 8, 384)    786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_89[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_86[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_8 (AveragePo  (None, 8, 8, 2048)  0           ['mixed9[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 8, 8, 320)    655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_88[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_91[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_92[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 8, 8, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 8, 8, 320)   960         ['conv2d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 8, 8, 192)   576         ['conv2d_93[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 8, 8, 768)    0           ['activation_87[0][0]',          \n",
      "                                                                  'activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 8, 8, 768)    0           ['activation_91[0][0]',          \n",
      "                                                                  'activation_92[0][0]']          \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 8, 8, 2048)   0           ['activation_85[0][0]',          \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_1[0][0]',          \n",
      "                                                                  'activation_93[0][0]']          \n",
      "                                                                                                  \n",
      " global_average_pooling2d_4 (Gl  (None, 2048)        0           ['mixed10[0][0]']                \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 2048)         0           ['global_average_pooling2d_4[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 4)            8196        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,810,980\n",
      "Trainable params: 8,196\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2 = build_model(0, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "223/223 [==============================] - 61s 255ms/step - loss: 1.1356 - accuracy: 0.5117 - val_loss: 0.7435 - val_accuracy: 0.7278\n",
      "Epoch 2/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.7657 - accuracy: 0.7015 - val_loss: 0.5569 - val_accuracy: 0.8057\n",
      "Epoch 3/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.6204 - accuracy: 0.7568 - val_loss: 0.4657 - val_accuracy: 0.8496\n",
      "Epoch 4/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.5293 - accuracy: 0.8026 - val_loss: 0.4072 - val_accuracy: 0.8643\n",
      "Epoch 5/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.4787 - accuracy: 0.8214 - val_loss: 0.3653 - val_accuracy: 0.8799\n",
      "Epoch 6/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.4272 - accuracy: 0.8439 - val_loss: 0.3314 - val_accuracy: 0.8976\n",
      "Epoch 7/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.3931 - accuracy: 0.8594 - val_loss: 0.3059 - val_accuracy: 0.9077\n",
      "Epoch 8/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.3668 - accuracy: 0.8693 - val_loss: 0.2843 - val_accuracy: 0.9149\n",
      "Epoch 9/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.3500 - accuracy: 0.8747 - val_loss: 0.2669 - val_accuracy: 0.9182\n",
      "Epoch 10/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.3270 - accuracy: 0.8833 - val_loss: 0.2539 - val_accuracy: 0.9204\n",
      "Epoch 11/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.3052 - accuracy: 0.8935 - val_loss: 0.2395 - val_accuracy: 0.9271\n",
      "Epoch 12/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.2968 - accuracy: 0.8935 - val_loss: 0.2290 - val_accuracy: 0.9347\n",
      "Epoch 13/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.2870 - accuracy: 0.9021 - val_loss: 0.2179 - val_accuracy: 0.9334\n",
      "Epoch 14/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.2741 - accuracy: 0.9031 - val_loss: 0.2109 - val_accuracy: 0.9393\n",
      "Epoch 15/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.2652 - accuracy: 0.9091 - val_loss: 0.2007 - val_accuracy: 0.9381\n",
      "Epoch 16/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.2540 - accuracy: 0.9118 - val_loss: 0.1936 - val_accuracy: 0.9448\n",
      "Epoch 17/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.2487 - accuracy: 0.9128 - val_loss: 0.1869 - val_accuracy: 0.9465\n",
      "Epoch 18/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.2370 - accuracy: 0.9192 - val_loss: 0.1839 - val_accuracy: 0.9431\n",
      "Epoch 19/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.2347 - accuracy: 0.9174 - val_loss: 0.1753 - val_accuracy: 0.9553\n",
      "Epoch 20/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.2314 - accuracy: 0.9217 - val_loss: 0.1712 - val_accuracy: 0.9566\n",
      "Epoch 21/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.2233 - accuracy: 0.9217 - val_loss: 0.1658 - val_accuracy: 0.9532\n",
      "Epoch 22/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.2208 - accuracy: 0.9226 - val_loss: 0.1623 - val_accuracy: 0.9570\n",
      "Epoch 23/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.2156 - accuracy: 0.9247 - val_loss: 0.1560 - val_accuracy: 0.9579\n",
      "Epoch 24/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.2043 - accuracy: 0.9317 - val_loss: 0.1525 - val_accuracy: 0.9612\n",
      "Epoch 25/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.2074 - accuracy: 0.9284 - val_loss: 0.1499 - val_accuracy: 0.9604\n",
      "Epoch 26/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.1993 - accuracy: 0.9316 - val_loss: 0.1453 - val_accuracy: 0.9625\n",
      "Epoch 27/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.2047 - accuracy: 0.9295 - val_loss: 0.1423 - val_accuracy: 0.9621\n",
      "Epoch 28/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.1960 - accuracy: 0.9309 - val_loss: 0.1393 - val_accuracy: 0.9646\n",
      "Epoch 29/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.1936 - accuracy: 0.9326 - val_loss: 0.1367 - val_accuracy: 0.9646\n",
      "Epoch 30/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1898 - accuracy: 0.9357 - val_loss: 0.1348 - val_accuracy: 0.9663\n",
      "Epoch 31/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.1882 - accuracy: 0.9361 - val_loss: 0.1310 - val_accuracy: 0.9671\n",
      "Epoch 32/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.1917 - accuracy: 0.9320 - val_loss: 0.1288 - val_accuracy: 0.9692\n",
      "Epoch 33/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.1804 - accuracy: 0.9393 - val_loss: 0.1263 - val_accuracy: 0.9692\n",
      "Epoch 34/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.1755 - accuracy: 0.9414 - val_loss: 0.1244 - val_accuracy: 0.9697\n",
      "Epoch 35/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.1823 - accuracy: 0.9357 - val_loss: 0.1222 - val_accuracy: 0.9701\n",
      "Epoch 36/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.1753 - accuracy: 0.9385 - val_loss: 0.1209 - val_accuracy: 0.9713\n",
      "Epoch 37/100\n",
      "223/223 [==============================] - 56s 249ms/step - loss: 0.1797 - accuracy: 0.9371 - val_loss: 0.1193 - val_accuracy: 0.9718\n",
      "Epoch 38/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.1760 - accuracy: 0.9410 - val_loss: 0.1165 - val_accuracy: 0.9713\n",
      "Epoch 39/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.1690 - accuracy: 0.9442 - val_loss: 0.1150 - val_accuracy: 0.9739\n",
      "Epoch 40/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.1713 - accuracy: 0.9380 - val_loss: 0.1129 - val_accuracy: 0.9739\n",
      "Epoch 41/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.1664 - accuracy: 0.9458 - val_loss: 0.1117 - val_accuracy: 0.9739\n",
      "Epoch 42/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.1653 - accuracy: 0.9427 - val_loss: 0.1111 - val_accuracy: 0.9709\n",
      "Epoch 43/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.1678 - accuracy: 0.9428 - val_loss: 0.1087 - val_accuracy: 0.9735\n",
      "Epoch 44/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.1611 - accuracy: 0.9431 - val_loss: 0.1089 - val_accuracy: 0.9735\n",
      "Epoch 45/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.1675 - accuracy: 0.9418 - val_loss: 0.1069 - val_accuracy: 0.9739\n",
      "Epoch 46/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.1597 - accuracy: 0.9458 - val_loss: 0.1053 - val_accuracy: 0.9730\n",
      "Epoch 47/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.1656 - accuracy: 0.9432 - val_loss: 0.1035 - val_accuracy: 0.9747\n",
      "Epoch 48/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.1588 - accuracy: 0.9446 - val_loss: 0.1046 - val_accuracy: 0.9730\n",
      "Epoch 49/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1525 - accuracy: 0.9475 - val_loss: 0.1023 - val_accuracy: 0.9756\n",
      "Epoch 50/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.1640 - accuracy: 0.9420 - val_loss: 0.1013 - val_accuracy: 0.9739\n",
      "Epoch 51/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1596 - accuracy: 0.9452 - val_loss: 0.0997 - val_accuracy: 0.9764\n",
      "Epoch 52/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1567 - accuracy: 0.9438 - val_loss: 0.1001 - val_accuracy: 0.9743\n",
      "Epoch 53/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1532 - accuracy: 0.9476 - val_loss: 0.0977 - val_accuracy: 0.9764\n",
      "Epoch 54/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.1485 - accuracy: 0.9538 - val_loss: 0.0979 - val_accuracy: 0.9756\n",
      "Epoch 55/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.1563 - accuracy: 0.9449 - val_loss: 0.0963 - val_accuracy: 0.9781\n",
      "Epoch 56/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1494 - accuracy: 0.9517 - val_loss: 0.0960 - val_accuracy: 0.9781\n",
      "Epoch 57/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.1475 - accuracy: 0.9469 - val_loss: 0.0945 - val_accuracy: 0.9785\n",
      "Epoch 58/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1496 - accuracy: 0.9456 - val_loss: 0.0935 - val_accuracy: 0.9764\n",
      "Epoch 59/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.1516 - accuracy: 0.9465 - val_loss: 0.0948 - val_accuracy: 0.9743\n",
      "Epoch 60/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.1447 - accuracy: 0.9501 - val_loss: 0.0928 - val_accuracy: 0.9772\n",
      "Epoch 61/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.1530 - accuracy: 0.9441 - val_loss: 0.0922 - val_accuracy: 0.9789\n",
      "Epoch 62/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.1454 - accuracy: 0.9483 - val_loss: 0.0903 - val_accuracy: 0.9777\n",
      "Epoch 63/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1493 - accuracy: 0.9448 - val_loss: 0.0902 - val_accuracy: 0.9785\n",
      "Epoch 64/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.1454 - accuracy: 0.9507 - val_loss: 0.0888 - val_accuracy: 0.9777\n",
      "Epoch 65/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1533 - accuracy: 0.9439 - val_loss: 0.0883 - val_accuracy: 0.9764\n",
      "Epoch 66/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.1428 - accuracy: 0.9501 - val_loss: 0.0870 - val_accuracy: 0.9810\n",
      "Epoch 67/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.1428 - accuracy: 0.9500 - val_loss: 0.0882 - val_accuracy: 0.9756\n",
      "Epoch 68/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.1431 - accuracy: 0.9507 - val_loss: 0.0867 - val_accuracy: 0.9789\n",
      "Epoch 69/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.1434 - accuracy: 0.9487 - val_loss: 0.0854 - val_accuracy: 0.9806\n",
      "Epoch 70/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1427 - accuracy: 0.9500 - val_loss: 0.0854 - val_accuracy: 0.9772\n",
      "Epoch 71/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.1405 - accuracy: 0.9508 - val_loss: 0.0845 - val_accuracy: 0.9810\n",
      "Epoch 72/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1472 - accuracy: 0.9472 - val_loss: 0.0839 - val_accuracy: 0.9789\n",
      "Epoch 73/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.1462 - accuracy: 0.9487 - val_loss: 0.0831 - val_accuracy: 0.9819\n",
      "Epoch 74/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.1392 - accuracy: 0.9504 - val_loss: 0.0833 - val_accuracy: 0.9789\n",
      "Epoch 75/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.1377 - accuracy: 0.9534 - val_loss: 0.0823 - val_accuracy: 0.9810\n",
      "Epoch 76/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.1482 - accuracy: 0.9461 - val_loss: 0.0821 - val_accuracy: 0.9798\n",
      "Epoch 77/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.1411 - accuracy: 0.9494 - val_loss: 0.0812 - val_accuracy: 0.9815\n",
      "Epoch 78/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1421 - accuracy: 0.9508 - val_loss: 0.0817 - val_accuracy: 0.9806\n",
      "Epoch 79/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1428 - accuracy: 0.9475 - val_loss: 0.0817 - val_accuracy: 0.9785\n",
      "Epoch 80/100\n",
      "223/223 [==============================] - 55s 244ms/step - loss: 0.1370 - accuracy: 0.9517 - val_loss: 0.0817 - val_accuracy: 0.9798\n",
      "Epoch 81/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.1368 - accuracy: 0.9541 - val_loss: 0.0799 - val_accuracy: 0.9819\n",
      "Epoch 82/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.1412 - accuracy: 0.9475 - val_loss: 0.0808 - val_accuracy: 0.9810\n",
      "Epoch 83/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.1391 - accuracy: 0.9522 - val_loss: 0.0800 - val_accuracy: 0.9806\n",
      "Epoch 84/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1303 - accuracy: 0.9549 - val_loss: 0.0804 - val_accuracy: 0.9789\n",
      "Epoch 85/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.1412 - accuracy: 0.9475 - val_loss: 0.0792 - val_accuracy: 0.9798\n",
      "Epoch 86/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1394 - accuracy: 0.9490 - val_loss: 0.0781 - val_accuracy: 0.9823\n",
      "Epoch 87/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1359 - accuracy: 0.9528 - val_loss: 0.0776 - val_accuracy: 0.9802\n",
      "Epoch 88/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.1333 - accuracy: 0.9498 - val_loss: 0.0765 - val_accuracy: 0.9819\n",
      "Epoch 89/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.1418 - accuracy: 0.9500 - val_loss: 0.0758 - val_accuracy: 0.9823\n",
      "Epoch 90/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.1374 - accuracy: 0.9525 - val_loss: 0.0755 - val_accuracy: 0.9823\n",
      "Epoch 91/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.1370 - accuracy: 0.9536 - val_loss: 0.0757 - val_accuracy: 0.9827\n",
      "Epoch 92/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1402 - accuracy: 0.9507 - val_loss: 0.0766 - val_accuracy: 0.9810\n",
      "Epoch 93/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.1358 - accuracy: 0.9480 - val_loss: 0.0748 - val_accuracy: 0.9831\n",
      "Epoch 94/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 0.1300 - accuracy: 0.9552 - val_loss: 0.0740 - val_accuracy: 0.9823\n",
      "Epoch 95/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 0.1337 - accuracy: 0.9531 - val_loss: 0.0739 - val_accuracy: 0.9827\n",
      "Epoch 96/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 0.1330 - accuracy: 0.9518 - val_loss: 0.0754 - val_accuracy: 0.9819\n",
      "Epoch 97/100\n",
      "223/223 [==============================] - 54s 240ms/step - loss: 0.1389 - accuracy: 0.9504 - val_loss: 0.0761 - val_accuracy: 0.9806\n",
      "Epoch 98/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 0.1387 - accuracy: 0.9472 - val_loss: 0.0742 - val_accuracy: 0.9831\n",
      "Epoch 99/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 0.1333 - accuracy: 0.9477 - val_loss: 0.0724 - val_accuracy: 0.9827\n",
      "Epoch 100/100\n",
      "223/223 [==============================] - 54s 240ms/step - loss: 0.1318 - accuracy: 0.9517 - val_loss: 0.0728 - val_accuracy: 0.9840\n"
     ]
    }
   ],
   "source": [
    "history_2, model_2 = fit_model(model_2, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Dense_128-DO_0.3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 299, 299, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 149, 149, 32  864         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 149, 149, 32  96         ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 149, 149, 32  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 147, 147, 32  9216        ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 147, 147, 32  96         ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 147, 147, 32  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 147, 147, 64  18432       ['activation_1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 147, 147, 64  192        ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 147, 147, 64  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 73, 73, 64)   0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 73, 73, 80)   5120        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 73, 73, 80)  240         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 73, 73, 80)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 71, 71, 192)  138240      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 71, 71, 192)  576        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 71, 71, 192)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0          ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 35, 35, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 35, 35, 96)   55296       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 35, 35, 48)  144         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 35, 35, 96)  288         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 35, 35, 48)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 35, 35, 96)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 35, 35, 192)  0          ['max_pooling2d_1[0][0]']        \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 35, 35, 64)   76800       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 35, 35, 32)   6144        ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 35, 35, 96)  288         ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 35, 35, 32)  96          ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 35, 35, 256)  0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_7[0][0]',           \n",
      "                                                                  'activation_10[0][0]',          \n",
      "                                                                  'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 35, 35, 64)  192         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 35, 35, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 35, 35, 48)  144         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 35, 35, 96)  288         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 35, 35, 256)  0          ['mixed0[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 35, 35, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 35, 35, 64)  192         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 35, 35, 64)  192         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 35, 35, 96)  288         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 35, 35, 64)  192         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 35, 35, 288)  0           ['activation_12[0][0]',          \n",
      "                                                                  'activation_14[0][0]',          \n",
      "                                                                  'activation_17[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 35, 35, 64)  192         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 35, 35, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 35, 35, 48)  144         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 35, 35, 96)  288         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 35, 35, 288)  0          ['mixed1[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 35, 35, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 35, 35, 64)  192         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 35, 35, 64)  192         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 35, 35, 96)  288         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 35, 35, 64)  192         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 35, 35, 288)  0           ['activation_19[0][0]',          \n",
      "                                                                  'activation_21[0][0]',          \n",
      "                                                                  'activation_24[0][0]',          \n",
      "                                                                  'activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 35, 35, 64)  192         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 35, 35, 96)  288         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 17, 17, 384)  995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 17, 17, 96)   82944       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 17, 17, 384)  1152       ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 17, 17, 96)  288         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 17, 17, 384)  0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 17, 17, 96)   0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0          ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 17, 17, 768)  0           ['activation_26[0][0]',          \n",
      "                                                                  'activation_29[0][0]',          \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 17, 17, 128)  384        ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 17, 17, 128)  384        ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 17, 17, 128)  384        ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 17, 17, 128)  384        ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 17, 17, 128)  384        ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 17, 17, 128)  384        ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 17, 17, 768)  0          ['mixed3[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 17, 17, 192)  576        ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 17, 17, 192)  576        ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 17, 17, 192)  576        ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 17, 17, 192)  576        ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 17, 17, 768)  0           ['activation_30[0][0]',          \n",
      "                                                                  'activation_33[0][0]',          \n",
      "                                                                  'activation_38[0][0]',          \n",
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 17, 17, 160)  480        ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 17, 17, 160)  480        ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 17, 17, 160)  480        ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 17, 17, 160)  480        ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 17, 17, 160)  480        ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 17, 17, 160)  480        ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, 17, 17, 768)  0          ['mixed4[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 17, 17, 192)  576        ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 17, 17, 192)  576        ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 17, 17, 192)  576        ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 17, 17, 192)  576        ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 17, 17, 768)  0           ['activation_40[0][0]',          \n",
      "                                                                  'activation_43[0][0]',          \n",
      "                                                                  'activation_48[0][0]',          \n",
      "                                                                  'activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 17, 17, 160)  480        ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 17, 17, 160)  480        ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 17, 17, 160)  480        ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 17, 17, 160)  480        ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 17, 17, 160)  480        ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 17, 17, 160)  480        ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, 17, 17, 768)  0          ['mixed5[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_5[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 17, 17, 192)  576        ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 17, 17, 192)  576        ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 17, 17, 192)  576        ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 17, 17, 192)  576        ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 17, 17, 768)  0           ['activation_50[0][0]',          \n",
      "                                                                  'activation_53[0][0]',          \n",
      "                                                                  'activation_58[0][0]',          \n",
      "                                                                  'activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 17, 17, 192)  576        ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 17, 17, 192)  576        ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 17, 17, 192)  576        ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 17, 17, 192)  576        ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 17, 17, 192)  576        ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 17, 17, 192)  576        ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (AveragePo  (None, 17, 17, 768)  0          ['mixed6[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_6[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 17, 17, 192)  576        ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 17, 17, 192)  576        ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 17, 17, 192)  576        ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 17, 17, 192)  576        ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 17, 17, 768)  0           ['activation_60[0][0]',          \n",
      "                                                                  'activation_63[0][0]',          \n",
      "                                                                  'activation_68[0][0]',          \n",
      "                                                                  'activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 17, 17, 192)  576        ['conv2d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_72[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 17, 17, 192)  576        ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_73[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 17, 17, 192)  576        ['conv2d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 17, 17, 192)  576        ['conv2d_74[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 8, 8, 320)    552960      ['activation_70[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 8, 8, 192)    331776      ['activation_74[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 8, 8, 320)   960         ['conv2d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 8, 8, 192)   576         ['conv2d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)   0           ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 8, 8, 1280)   0           ['activation_71[0][0]',          \n",
      "                                                                  'activation_75[0][0]',          \n",
      "                                                                  'max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 8, 8, 448)    573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_80[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 8, 8, 384)    491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_80[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_7 (AveragePo  (None, 8, 8, 1280)  0           ['mixed8[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 8, 8, 320)    409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_78[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_79[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_82[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_83[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 8, 8, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 8, 8, 320)   960         ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 8, 8, 192)   576         ['conv2d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 8, 8, 768)    0           ['activation_78[0][0]',          \n",
      "                                                                  'activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 8, 8, 768)    0           ['activation_82[0][0]',          \n",
      "                                                                  'activation_83[0][0]']          \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, 8, 8, 2048)   0           ['activation_76[0][0]',          \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate[0][0]',            \n",
      "                                                                  'activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 8, 8, 448)    917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 8, 8, 384)    786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_89[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_86[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_8 (AveragePo  (None, 8, 8, 2048)  0           ['mixed9[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 8, 8, 320)    655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_88[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_91[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_92[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 8, 8, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 8, 8, 320)   960         ['conv2d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 8, 8, 192)   576         ['conv2d_93[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 8, 8, 768)    0           ['activation_87[0][0]',          \n",
      "                                                                  'activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 8, 8, 768)    0           ['activation_91[0][0]',          \n",
      "                                                                  'activation_92[0][0]']          \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 8, 8, 2048)   0           ['activation_85[0][0]',          \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_1[0][0]',          \n",
      "                                                                  'activation_93[0][0]']          \n",
      "                                                                                                  \n",
      " global_average_pooling2d_5 (Gl  (None, 2048)        0           ['mixed10[0][0]']                \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 128)          262272      ['global_average_pooling2d_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 128)          0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 4)            516         ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 22,065,572\n",
      "Trainable params: 262,788\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3 = build_model(128, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "223/223 [==============================] - 93s 391ms/step - loss: 0.6388 - accuracy: 0.7532 - val_loss: 0.3264 - val_accuracy: 0.9027\n",
      "Epoch 2/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 0.3123 - accuracy: 0.8949 - val_loss: 0.2147 - val_accuracy: 0.9423\n",
      "Epoch 3/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.2211 - accuracy: 0.9291 - val_loss: 0.1644 - val_accuracy: 0.9570\n",
      "Epoch 4/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.1742 - accuracy: 0.9483 - val_loss: 0.1285 - val_accuracy: 0.9646\n",
      "Epoch 5/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.1401 - accuracy: 0.9586 - val_loss: 0.1101 - val_accuracy: 0.9730\n",
      "Epoch 6/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.1173 - accuracy: 0.9681 - val_loss: 0.0990 - val_accuracy: 0.9751\n",
      "Epoch 7/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0963 - accuracy: 0.9740 - val_loss: 0.0805 - val_accuracy: 0.9815\n",
      "Epoch 8/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0867 - accuracy: 0.9767 - val_loss: 0.0732 - val_accuracy: 0.9819\n",
      "Epoch 9/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0735 - accuracy: 0.9809 - val_loss: 0.0681 - val_accuracy: 0.9848\n",
      "Epoch 10/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0644 - accuracy: 0.9844 - val_loss: 0.0578 - val_accuracy: 0.9848\n",
      "Epoch 11/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0530 - accuracy: 0.9888 - val_loss: 0.0540 - val_accuracy: 0.9874\n",
      "Epoch 12/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0495 - accuracy: 0.9889 - val_loss: 0.0502 - val_accuracy: 0.9886\n",
      "Epoch 13/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0449 - accuracy: 0.9904 - val_loss: 0.0509 - val_accuracy: 0.9878\n",
      "Epoch 14/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0397 - accuracy: 0.9914 - val_loss: 0.0476 - val_accuracy: 0.9869\n",
      "Epoch 15/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0359 - accuracy: 0.9931 - val_loss: 0.0396 - val_accuracy: 0.9882\n",
      "Epoch 16/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0297 - accuracy: 0.9951 - val_loss: 0.0372 - val_accuracy: 0.9886\n",
      "Epoch 17/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0268 - accuracy: 0.9961 - val_loss: 0.0336 - val_accuracy: 0.9903\n",
      "Epoch 18/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0243 - accuracy: 0.9951 - val_loss: 0.0319 - val_accuracy: 0.9895\n",
      "Epoch 19/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0205 - accuracy: 0.9973 - val_loss: 0.0295 - val_accuracy: 0.9920\n",
      "Epoch 20/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0188 - accuracy: 0.9980 - val_loss: 0.0290 - val_accuracy: 0.9924\n",
      "Epoch 21/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0181 - accuracy: 0.9970 - val_loss: 0.0303 - val_accuracy: 0.9920\n",
      "Epoch 22/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0170 - accuracy: 0.9979 - val_loss: 0.0289 - val_accuracy: 0.9912\n",
      "Epoch 23/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0135 - accuracy: 0.9990 - val_loss: 0.0256 - val_accuracy: 0.9928\n",
      "Epoch 24/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0138 - accuracy: 0.9986 - val_loss: 0.0245 - val_accuracy: 0.9924\n",
      "Epoch 25/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0108 - accuracy: 0.9986 - val_loss: 0.0246 - val_accuracy: 0.9924\n",
      "Epoch 26/100\n",
      "223/223 [==============================] - 55s 244ms/step - loss: 0.0112 - accuracy: 0.9986 - val_loss: 0.0243 - val_accuracy: 0.9912\n",
      "Epoch 27/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0088 - accuracy: 0.9993 - val_loss: 0.0227 - val_accuracy: 0.9941\n",
      "Epoch 28/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0084 - accuracy: 0.9993 - val_loss: 0.0217 - val_accuracy: 0.9937\n",
      "Epoch 29/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0077 - accuracy: 0.9999 - val_loss: 0.0218 - val_accuracy: 0.9924\n",
      "Epoch 30/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0077 - accuracy: 0.9996 - val_loss: 0.0233 - val_accuracy: 0.9920\n",
      "Epoch 31/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0061 - accuracy: 0.9999 - val_loss: 0.0199 - val_accuracy: 0.9941\n",
      "Epoch 32/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0059 - accuracy: 0.9999 - val_loss: 0.0208 - val_accuracy: 0.9933\n",
      "Epoch 33/100\n",
      "223/223 [==============================] - 55s 244ms/step - loss: 0.0057 - accuracy: 0.9996 - val_loss: 0.0196 - val_accuracy: 0.9945\n",
      "Epoch 34/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0057 - accuracy: 0.9993 - val_loss: 0.0208 - val_accuracy: 0.9924\n",
      "Epoch 35/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0057 - accuracy: 0.9999 - val_loss: 0.0195 - val_accuracy: 0.9933\n",
      "Epoch 36/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0043 - accuracy: 0.9997 - val_loss: 0.0195 - val_accuracy: 0.9933\n",
      "Epoch 37/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0048 - accuracy: 0.9997 - val_loss: 0.0196 - val_accuracy: 0.9924\n",
      "Epoch 38/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0038 - accuracy: 0.9997 - val_loss: 0.0188 - val_accuracy: 0.9941\n",
      "Epoch 39/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0035 - accuracy: 0.9999 - val_loss: 0.0189 - val_accuracy: 0.9933\n",
      "Epoch 40/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.0190 - val_accuracy: 0.9949\n",
      "Epoch 41/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 0.9949\n",
      "Epoch 42/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 0.9945\n",
      "Epoch 43/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0173 - val_accuracy: 0.9949\n",
      "Epoch 44/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 0.9937\n",
      "Epoch 45/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.0184 - val_accuracy: 0.9945\n",
      "Epoch 46/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 0.9937\n",
      "Epoch 47/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.0200 - val_accuracy: 0.9928\n",
      "Epoch 48/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 0.0238 - val_accuracy: 0.9933\n",
      "Epoch 49/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.0174 - val_accuracy: 0.9954\n",
      "Epoch 50/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 0.9949\n",
      "Epoch 51/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 0.9949\n",
      "Epoch 52/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0180 - val_accuracy: 0.9945\n",
      "Epoch 53/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 0.9928\n",
      "Epoch 54/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0198 - val_accuracy: 0.9941\n",
      "Epoch 55/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0188 - val_accuracy: 0.9941\n",
      "Epoch 56/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0213 - val_accuracy: 0.9941\n",
      "Epoch 57/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0187 - val_accuracy: 0.9941\n",
      "Epoch 58/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0202 - val_accuracy: 0.9928\n",
      "Epoch 59/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 0.9933\n",
      "Epoch 60/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0165 - val_accuracy: 0.9933\n",
      "Epoch 61/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 6.9503e-04 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 0.9945\n",
      "Epoch 62/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 7.0138e-04 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9954\n",
      "Epoch 63/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 5.8797e-04 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 0.9945\n",
      "Epoch 64/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 5.5035e-04 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9958\n",
      "Epoch 65/100\n",
      "223/223 [==============================] - 55s 244ms/step - loss: 5.9714e-04 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9945\n",
      "Epoch 66/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 5.6688e-04 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 0.9954\n",
      "Epoch 67/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 6.2904e-04 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 0.9937\n",
      "Epoch 68/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0176 - val_accuracy: 0.9933\n",
      "Epoch 69/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 7.2739e-04 - accuracy: 1.0000 - val_loss: 0.0180 - val_accuracy: 0.9937\n",
      "Epoch 70/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 4.7432e-04 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 0.9937\n",
      "Epoch 71/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 3.5287e-04 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 0.9945\n",
      "Epoch 72/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 3.1184e-04 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 0.9937\n",
      "Epoch 73/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 3.1919e-04 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 0.9945\n",
      "Epoch 74/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 5.3772e-04 - accuracy: 1.0000 - val_loss: 0.0195 - val_accuracy: 0.9937\n",
      "Epoch 75/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 4.8630e-04 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 0.9941\n",
      "Epoch 76/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0187 - val_accuracy: 0.9937\n",
      "Epoch 77/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 3.6529e-04 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 0.9924\n",
      "Epoch 78/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0179 - val_accuracy: 0.9941\n",
      "Epoch 79/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 6.7009e-04 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 0.9941\n",
      "Epoch 80/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 3.3238e-04 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 0.9945\n",
      "Epoch 81/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 6.3304e-04 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 0.9949\n",
      "Epoch 82/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0174 - val_accuracy: 0.9962\n",
      "Epoch 83/100\n",
      "223/223 [==============================] - 55s 244ms/step - loss: 3.1240e-04 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 0.9945\n",
      "Epoch 84/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 4.3124e-04 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9966\n",
      "Epoch 85/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 1.7462e-04 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 0.9949\n",
      "Epoch 86/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 8.8441e-04 - accuracy: 0.9999 - val_loss: 0.0216 - val_accuracy: 0.9937\n",
      "Epoch 87/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 5.2722e-04 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 0.9937\n",
      "Epoch 88/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 3.6210e-04 - accuracy: 1.0000 - val_loss: 0.0183 - val_accuracy: 0.9958\n",
      "Epoch 89/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 1.7677e-04 - accuracy: 1.0000 - val_loss: 0.0208 - val_accuracy: 0.9949\n",
      "Epoch 90/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 6.0696e-04 - accuracy: 0.9999 - val_loss: 0.0244 - val_accuracy: 0.9933\n",
      "Epoch 91/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0168 - val_accuracy: 0.9949\n",
      "Epoch 92/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 4.9756e-04 - accuracy: 1.0000 - val_loss: 0.0180 - val_accuracy: 0.9949\n",
      "Epoch 93/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 2.3197e-04 - accuracy: 1.0000 - val_loss: 0.0205 - val_accuracy: 0.9941\n",
      "Epoch 94/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 3.1842e-04 - accuracy: 1.0000 - val_loss: 0.0172 - val_accuracy: 0.9945\n",
      "Epoch 95/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 1.5415e-04 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 0.9949\n",
      "Epoch 96/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 1.5771e-04 - accuracy: 1.0000 - val_loss: 0.0172 - val_accuracy: 0.9949\n",
      "Epoch 97/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 5.5291e-04 - accuracy: 0.9997 - val_loss: 0.0190 - val_accuracy: 0.9924\n",
      "Epoch 98/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0163 - val_accuracy: 0.9933\n",
      "Epoch 99/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 8.0277e-04 - accuracy: 0.9997 - val_loss: 0.0211 - val_accuracy: 0.9933\n",
      "Epoch 100/100\n",
      "223/223 [==============================] - 54s 240ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0170 - val_accuracy: 0.9954\n"
     ]
    }
   ],
   "source": [
    "history_3, model_3 = fit_model(model_3, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"100_Dense_0-DO_0.3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 299, 299, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 149, 149, 32  864         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 149, 149, 32  96         ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 149, 149, 32  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 147, 147, 32  9216        ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 147, 147, 32  96         ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 147, 147, 32  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 147, 147, 64  18432       ['activation_1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 147, 147, 64  192        ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 147, 147, 64  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 73, 73, 64)   0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 73, 73, 80)   5120        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 73, 73, 80)  240         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 73, 73, 80)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 71, 71, 192)  138240      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 71, 71, 192)  576        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 71, 71, 192)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0          ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 35, 35, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 35, 35, 96)   55296       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 35, 35, 48)  144         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 35, 35, 96)  288         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 35, 35, 48)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 35, 35, 96)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 35, 35, 192)  0          ['max_pooling2d_1[0][0]']        \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 35, 35, 64)   76800       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 35, 35, 32)   6144        ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 35, 35, 96)  288         ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 35, 35, 32)  96          ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 35, 35, 256)  0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_7[0][0]',           \n",
      "                                                                  'activation_10[0][0]',          \n",
      "                                                                  'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 35, 35, 64)  192         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 35, 35, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 35, 35, 48)  144         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 35, 35, 96)  288         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 35, 35, 256)  0          ['mixed0[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 35, 35, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 35, 35, 64)  192         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 35, 35, 64)  192         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 35, 35, 96)  288         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 35, 35, 64)  192         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 35, 35, 288)  0           ['activation_12[0][0]',          \n",
      "                                                                  'activation_14[0][0]',          \n",
      "                                                                  'activation_17[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 35, 35, 64)  192         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 35, 35, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 35, 35, 48)  144         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 35, 35, 96)  288         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 35, 35, 288)  0          ['mixed1[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 35, 35, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 35, 35, 64)  192         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 35, 35, 64)  192         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 35, 35, 96)  288         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 35, 35, 64)  192         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 35, 35, 288)  0           ['activation_19[0][0]',          \n",
      "                                                                  'activation_21[0][0]',          \n",
      "                                                                  'activation_24[0][0]',          \n",
      "                                                                  'activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 35, 35, 64)  192         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 35, 35, 96)  288         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 17, 17, 384)  995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 17, 17, 96)   82944       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 17, 17, 384)  1152       ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 17, 17, 96)  288         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 17, 17, 384)  0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 17, 17, 96)   0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0          ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 17, 17, 768)  0           ['activation_26[0][0]',          \n",
      "                                                                  'activation_29[0][0]',          \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 17, 17, 128)  384        ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 17, 17, 128)  384        ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 17, 17, 128)  384        ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 17, 17, 128)  384        ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 17, 17, 128)  384        ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 17, 17, 128)  384        ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 17, 17, 768)  0          ['mixed3[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 17, 17, 192)  576        ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 17, 17, 192)  576        ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 17, 17, 192)  576        ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 17, 17, 192)  576        ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 17, 17, 768)  0           ['activation_30[0][0]',          \n",
      "                                                                  'activation_33[0][0]',          \n",
      "                                                                  'activation_38[0][0]',          \n",
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 17, 17, 160)  480        ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 17, 17, 160)  480        ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 17, 17, 160)  480        ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 17, 17, 160)  480        ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 17, 17, 160)  480        ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 17, 17, 160)  480        ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, 17, 17, 768)  0          ['mixed4[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 17, 17, 192)  576        ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 17, 17, 192)  576        ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 17, 17, 192)  576        ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 17, 17, 192)  576        ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 17, 17, 768)  0           ['activation_40[0][0]',          \n",
      "                                                                  'activation_43[0][0]',          \n",
      "                                                                  'activation_48[0][0]',          \n",
      "                                                                  'activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 17, 17, 160)  480        ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 17, 17, 160)  480        ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 17, 17, 160)  480        ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 17, 17, 160)  480        ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 17, 17, 160)  480        ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 17, 17, 160)  480        ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, 17, 17, 768)  0          ['mixed5[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_5[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 17, 17, 192)  576        ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 17, 17, 192)  576        ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 17, 17, 192)  576        ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 17, 17, 192)  576        ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 17, 17, 768)  0           ['activation_50[0][0]',          \n",
      "                                                                  'activation_53[0][0]',          \n",
      "                                                                  'activation_58[0][0]',          \n",
      "                                                                  'activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 17, 17, 192)  576        ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 17, 17, 192)  576        ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 17, 17, 192)  576        ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 17, 17, 192)  576        ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 17, 17, 192)  576        ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 17, 17, 192)  576        ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (AveragePo  (None, 17, 17, 768)  0          ['mixed6[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_6[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 17, 17, 192)  576        ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 17, 17, 192)  576        ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 17, 17, 192)  576        ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 17, 17, 192)  576        ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 17, 17, 768)  0           ['activation_60[0][0]',          \n",
      "                                                                  'activation_63[0][0]',          \n",
      "                                                                  'activation_68[0][0]',          \n",
      "                                                                  'activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 17, 17, 192)  576        ['conv2d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_72[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 17, 17, 192)  576        ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_73[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 17, 17, 192)  576        ['conv2d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 17, 17, 192)  576        ['conv2d_74[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 8, 8, 320)    552960      ['activation_70[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 8, 8, 192)    331776      ['activation_74[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 8, 8, 320)   960         ['conv2d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 8, 8, 192)   576         ['conv2d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)   0           ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 8, 8, 1280)   0           ['activation_71[0][0]',          \n",
      "                                                                  'activation_75[0][0]',          \n",
      "                                                                  'max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 8, 8, 448)    573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_80[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 8, 8, 384)    491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_80[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_7 (AveragePo  (None, 8, 8, 1280)  0           ['mixed8[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 8, 8, 320)    409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_78[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_79[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_82[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_83[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 8, 8, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 8, 8, 320)   960         ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 8, 8, 192)   576         ['conv2d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 8, 8, 768)    0           ['activation_78[0][0]',          \n",
      "                                                                  'activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 8, 8, 768)    0           ['activation_82[0][0]',          \n",
      "                                                                  'activation_83[0][0]']          \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, 8, 8, 2048)   0           ['activation_76[0][0]',          \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate[0][0]',            \n",
      "                                                                  'activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 8, 8, 448)    917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 8, 8, 384)    786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_89[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_86[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_8 (AveragePo  (None, 8, 8, 2048)  0           ['mixed9[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 8, 8, 320)    655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_88[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_91[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_92[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 8, 8, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 8, 8, 320)   960         ['conv2d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 8, 8, 192)   576         ['conv2d_93[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 8, 8, 768)    0           ['activation_87[0][0]',          \n",
      "                                                                  'activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 8, 8, 768)    0           ['activation_91[0][0]',          \n",
      "                                                                  'activation_92[0][0]']          \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 8, 8, 2048)   0           ['activation_85[0][0]',          \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_1[0][0]',          \n",
      "                                                                  'activation_93[0][0]']          \n",
      "                                                                                                  \n",
      " global_average_pooling2d_6 (Gl  (None, 2048)        0           ['mixed10[0][0]']                \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 2048)         0           ['global_average_pooling2d_6[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 4)            8196        ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,810,980\n",
      "Trainable params: 8,196\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_4 = build_model(0, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "223/223 [==============================] - 101s 428ms/step - loss: 1.1022 - accuracy: 0.5310 - val_loss: 0.7380 - val_accuracy: 0.7539\n",
      "Epoch 2/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.6938 - accuracy: 0.7421 - val_loss: 0.5401 - val_accuracy: 0.8150\n",
      "Epoch 3/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.5422 - accuracy: 0.8044 - val_loss: 0.4435 - val_accuracy: 0.8592\n",
      "Epoch 4/100\n",
      "223/223 [==============================] - 52s 232ms/step - loss: 0.4608 - accuracy: 0.8370 - val_loss: 0.3805 - val_accuracy: 0.8841\n",
      "Epoch 5/100\n",
      "223/223 [==============================] - 52s 231ms/step - loss: 0.4072 - accuracy: 0.8602 - val_loss: 0.3368 - val_accuracy: 0.9014\n",
      "Epoch 6/100\n",
      "223/223 [==============================] - 51s 230ms/step - loss: 0.3670 - accuracy: 0.8776 - val_loss: 0.3040 - val_accuracy: 0.9102\n",
      "Epoch 7/100\n",
      "223/223 [==============================] - 52s 231ms/step - loss: 0.3373 - accuracy: 0.8841 - val_loss: 0.2773 - val_accuracy: 0.9178\n",
      "Epoch 8/100\n",
      "223/223 [==============================] - 52s 232ms/step - loss: 0.3056 - accuracy: 0.9010 - val_loss: 0.2571 - val_accuracy: 0.9254\n",
      "Epoch 9/100\n",
      "223/223 [==============================] - 52s 232ms/step - loss: 0.2887 - accuracy: 0.9062 - val_loss: 0.2408 - val_accuracy: 0.9313\n",
      "Epoch 10/100\n",
      "223/223 [==============================] - 67s 300ms/step - loss: 0.2709 - accuracy: 0.9149 - val_loss: 0.2258 - val_accuracy: 0.9355\n",
      "Epoch 11/100\n",
      "223/223 [==============================] - 63s 281ms/step - loss: 0.2544 - accuracy: 0.9187 - val_loss: 0.2135 - val_accuracy: 0.9389\n",
      "Epoch 12/100\n",
      "223/223 [==============================] - 52s 232ms/step - loss: 0.2415 - accuracy: 0.9229 - val_loss: 0.2020 - val_accuracy: 0.9452\n",
      "Epoch 13/100\n",
      "223/223 [==============================] - 52s 232ms/step - loss: 0.2315 - accuracy: 0.9257 - val_loss: 0.1914 - val_accuracy: 0.9465\n",
      "Epoch 14/100\n",
      "223/223 [==============================] - 52s 232ms/step - loss: 0.2212 - accuracy: 0.9312 - val_loss: 0.1859 - val_accuracy: 0.9507\n",
      "Epoch 15/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 0.2106 - accuracy: 0.9330 - val_loss: 0.1757 - val_accuracy: 0.9532\n",
      "Epoch 16/100\n",
      "223/223 [==============================] - 52s 234ms/step - loss: 0.2020 - accuracy: 0.9350 - val_loss: 0.1689 - val_accuracy: 0.9558\n",
      "Epoch 17/100\n",
      "223/223 [==============================] - 52s 234ms/step - loss: 0.1955 - accuracy: 0.9364 - val_loss: 0.1630 - val_accuracy: 0.9562\n",
      "Epoch 18/100\n",
      "223/223 [==============================] - 53s 236ms/step - loss: 0.1889 - accuracy: 0.9404 - val_loss: 0.1566 - val_accuracy: 0.9604\n",
      "Epoch 19/100\n",
      "223/223 [==============================] - 52s 234ms/step - loss: 0.1844 - accuracy: 0.9438 - val_loss: 0.1499 - val_accuracy: 0.9633\n",
      "Epoch 20/100\n",
      "223/223 [==============================] - 52s 234ms/step - loss: 0.1778 - accuracy: 0.9458 - val_loss: 0.1469 - val_accuracy: 0.9604\n",
      "Epoch 21/100\n",
      "223/223 [==============================] - 52s 234ms/step - loss: 0.1722 - accuracy: 0.9455 - val_loss: 0.1405 - val_accuracy: 0.9638\n",
      "Epoch 22/100\n",
      "223/223 [==============================] - 52s 234ms/step - loss: 0.1673 - accuracy: 0.9493 - val_loss: 0.1360 - val_accuracy: 0.9680\n",
      "Epoch 23/100\n",
      "223/223 [==============================] - 52s 234ms/step - loss: 0.1629 - accuracy: 0.9500 - val_loss: 0.1328 - val_accuracy: 0.9676\n",
      "Epoch 24/100\n",
      "223/223 [==============================] - 53s 236ms/step - loss: 0.1601 - accuracy: 0.9513 - val_loss: 0.1323 - val_accuracy: 0.9638\n",
      "Epoch 25/100\n",
      "223/223 [==============================] - 52s 235ms/step - loss: 0.1538 - accuracy: 0.9524 - val_loss: 0.1245 - val_accuracy: 0.9692\n",
      "Epoch 26/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 0.1509 - accuracy: 0.9543 - val_loss: 0.1212 - val_accuracy: 0.9705\n",
      "Epoch 27/100\n",
      "223/223 [==============================] - 52s 235ms/step - loss: 0.1508 - accuracy: 0.9513 - val_loss: 0.1191 - val_accuracy: 0.9701\n",
      "Epoch 28/100\n",
      "223/223 [==============================] - 52s 235ms/step - loss: 0.1439 - accuracy: 0.9550 - val_loss: 0.1152 - val_accuracy: 0.9718\n",
      "Epoch 29/100\n",
      "223/223 [==============================] - 53s 236ms/step - loss: 0.1401 - accuracy: 0.9590 - val_loss: 0.1138 - val_accuracy: 0.9713\n",
      "Epoch 30/100\n",
      "223/223 [==============================] - 52s 234ms/step - loss: 0.1396 - accuracy: 0.9555 - val_loss: 0.1102 - val_accuracy: 0.9768\n",
      "Epoch 31/100\n",
      "223/223 [==============================] - 52s 234ms/step - loss: 0.1348 - accuracy: 0.9593 - val_loss: 0.1072 - val_accuracy: 0.9739\n",
      "Epoch 32/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 0.1321 - accuracy: 0.9608 - val_loss: 0.1052 - val_accuracy: 0.9764\n",
      "Epoch 33/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 0.1292 - accuracy: 0.9619 - val_loss: 0.1044 - val_accuracy: 0.9756\n",
      "Epoch 34/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 0.1303 - accuracy: 0.9593 - val_loss: 0.1027 - val_accuracy: 0.9735\n",
      "Epoch 35/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 0.1211 - accuracy: 0.9654 - val_loss: 0.0995 - val_accuracy: 0.9751\n",
      "Epoch 36/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 0.1205 - accuracy: 0.9642 - val_loss: 0.0970 - val_accuracy: 0.9772\n",
      "Epoch 37/100\n",
      "223/223 [==============================] - 52s 232ms/step - loss: 0.1234 - accuracy: 0.9636 - val_loss: 0.0951 - val_accuracy: 0.9777\n",
      "Epoch 38/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 0.1176 - accuracy: 0.9653 - val_loss: 0.0928 - val_accuracy: 0.9789\n",
      "Epoch 39/100\n",
      "223/223 [==============================] - 52s 234ms/step - loss: 0.1145 - accuracy: 0.9668 - val_loss: 0.0911 - val_accuracy: 0.9785\n",
      "Epoch 40/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 0.1170 - accuracy: 0.9652 - val_loss: 0.0912 - val_accuracy: 0.9789\n",
      "Epoch 41/100\n",
      "223/223 [==============================] - 53s 237ms/step - loss: 0.1141 - accuracy: 0.9639 - val_loss: 0.0898 - val_accuracy: 0.9785\n",
      "Epoch 42/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.1117 - accuracy: 0.9674 - val_loss: 0.0876 - val_accuracy: 0.9794\n",
      "Epoch 43/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.1117 - accuracy: 0.9687 - val_loss: 0.0867 - val_accuracy: 0.9802\n",
      "Epoch 44/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.1086 - accuracy: 0.9674 - val_loss: 0.0848 - val_accuracy: 0.9798\n",
      "Epoch 45/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.1101 - accuracy: 0.9681 - val_loss: 0.0831 - val_accuracy: 0.9823\n",
      "Epoch 46/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.1098 - accuracy: 0.9649 - val_loss: 0.0816 - val_accuracy: 0.9819\n",
      "Epoch 47/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.1029 - accuracy: 0.9699 - val_loss: 0.0802 - val_accuracy: 0.9819\n",
      "Epoch 48/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.1010 - accuracy: 0.9690 - val_loss: 0.0795 - val_accuracy: 0.9827\n",
      "Epoch 49/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.1019 - accuracy: 0.9704 - val_loss: 0.0782 - val_accuracy: 0.9827\n",
      "Epoch 50/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.1043 - accuracy: 0.9688 - val_loss: 0.0781 - val_accuracy: 0.9840\n",
      "Epoch 51/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0981 - accuracy: 0.9690 - val_loss: 0.0786 - val_accuracy: 0.9819\n",
      "Epoch 52/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.1027 - accuracy: 0.9692 - val_loss: 0.0753 - val_accuracy: 0.9836\n",
      "Epoch 53/100\n",
      "223/223 [==============================] - 79s 356ms/step - loss: 0.0966 - accuracy: 0.9715 - val_loss: 0.0787 - val_accuracy: 0.9810\n",
      "Epoch 54/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0975 - accuracy: 0.9702 - val_loss: 0.0753 - val_accuracy: 0.9840\n",
      "Epoch 55/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0961 - accuracy: 0.9713 - val_loss: 0.0734 - val_accuracy: 0.9848\n",
      "Epoch 56/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0976 - accuracy: 0.9706 - val_loss: 0.0716 - val_accuracy: 0.9836\n",
      "Epoch 57/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0938 - accuracy: 0.9732 - val_loss: 0.0704 - val_accuracy: 0.9844\n",
      "Epoch 58/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0945 - accuracy: 0.9722 - val_loss: 0.0698 - val_accuracy: 0.9836\n",
      "Epoch 59/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0904 - accuracy: 0.9727 - val_loss: 0.0701 - val_accuracy: 0.9827\n",
      "Epoch 60/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0902 - accuracy: 0.9729 - val_loss: 0.0684 - val_accuracy: 0.9848\n",
      "Epoch 61/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0922 - accuracy: 0.9697 - val_loss: 0.0677 - val_accuracy: 0.9857\n",
      "Epoch 62/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0914 - accuracy: 0.9719 - val_loss: 0.0682 - val_accuracy: 0.9844\n",
      "Epoch 63/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0908 - accuracy: 0.9715 - val_loss: 0.0674 - val_accuracy: 0.9844\n",
      "Epoch 64/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0876 - accuracy: 0.9729 - val_loss: 0.0657 - val_accuracy: 0.9836\n",
      "Epoch 65/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0857 - accuracy: 0.9751 - val_loss: 0.0648 - val_accuracy: 0.9844\n",
      "Epoch 66/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0877 - accuracy: 0.9740 - val_loss: 0.0648 - val_accuracy: 0.9836\n",
      "Epoch 67/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0826 - accuracy: 0.9770 - val_loss: 0.0642 - val_accuracy: 0.9853\n",
      "Epoch 68/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0816 - accuracy: 0.9758 - val_loss: 0.0629 - val_accuracy: 0.9848\n",
      "Epoch 69/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0870 - accuracy: 0.9763 - val_loss: 0.0625 - val_accuracy: 0.9865\n",
      "Epoch 70/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0831 - accuracy: 0.9760 - val_loss: 0.0634 - val_accuracy: 0.9844\n",
      "Epoch 71/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0858 - accuracy: 0.9729 - val_loss: 0.0612 - val_accuracy: 0.9853\n",
      "Epoch 72/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0822 - accuracy: 0.9765 - val_loss: 0.0610 - val_accuracy: 0.9853\n",
      "Epoch 73/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0870 - accuracy: 0.9706 - val_loss: 0.0610 - val_accuracy: 0.9874\n",
      "Epoch 74/100\n",
      "223/223 [==============================] - 72s 324ms/step - loss: 0.0834 - accuracy: 0.9757 - val_loss: 0.0598 - val_accuracy: 0.9857\n",
      "Epoch 75/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0828 - accuracy: 0.9747 - val_loss: 0.0594 - val_accuracy: 0.9853\n",
      "Epoch 76/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0835 - accuracy: 0.9761 - val_loss: 0.0585 - val_accuracy: 0.9853\n",
      "Epoch 77/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0812 - accuracy: 0.9763 - val_loss: 0.0583 - val_accuracy: 0.9882\n",
      "Epoch 78/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0833 - accuracy: 0.9744 - val_loss: 0.0591 - val_accuracy: 0.9861\n",
      "Epoch 79/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0771 - accuracy: 0.9768 - val_loss: 0.0575 - val_accuracy: 0.9861\n",
      "Epoch 80/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0835 - accuracy: 0.9746 - val_loss: 0.0572 - val_accuracy: 0.9853\n",
      "Epoch 81/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0862 - accuracy: 0.9715 - val_loss: 0.0570 - val_accuracy: 0.9853\n",
      "Epoch 82/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0820 - accuracy: 0.9750 - val_loss: 0.0585 - val_accuracy: 0.9861\n",
      "Epoch 83/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0792 - accuracy: 0.9751 - val_loss: 0.0556 - val_accuracy: 0.9874\n",
      "Epoch 84/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0762 - accuracy: 0.9764 - val_loss: 0.0549 - val_accuracy: 0.9878\n",
      "Epoch 85/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0783 - accuracy: 0.9753 - val_loss: 0.0552 - val_accuracy: 0.9869\n",
      "Epoch 86/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0790 - accuracy: 0.9740 - val_loss: 0.0548 - val_accuracy: 0.9882\n",
      "Epoch 87/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0760 - accuracy: 0.9775 - val_loss: 0.0578 - val_accuracy: 0.9861\n",
      "Epoch 88/100\n",
      "223/223 [==============================] - 55s 244ms/step - loss: 0.0762 - accuracy: 0.9757 - val_loss: 0.0552 - val_accuracy: 0.9857\n",
      "Epoch 89/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0795 - accuracy: 0.9739 - val_loss: 0.0533 - val_accuracy: 0.9878\n",
      "Epoch 90/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0764 - accuracy: 0.9751 - val_loss: 0.0540 - val_accuracy: 0.9861\n",
      "Epoch 91/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0775 - accuracy: 0.9753 - val_loss: 0.0526 - val_accuracy: 0.9874\n",
      "Epoch 92/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0757 - accuracy: 0.9767 - val_loss: 0.0525 - val_accuracy: 0.9874\n",
      "Epoch 93/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0748 - accuracy: 0.9760 - val_loss: 0.0521 - val_accuracy: 0.9878\n",
      "Epoch 94/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0757 - accuracy: 0.9760 - val_loss: 0.0527 - val_accuracy: 0.9874\n",
      "Epoch 95/100\n",
      "223/223 [==============================] - 55s 244ms/step - loss: 0.0742 - accuracy: 0.9767 - val_loss: 0.0524 - val_accuracy: 0.9878\n",
      "Epoch 96/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0743 - accuracy: 0.9779 - val_loss: 0.0508 - val_accuracy: 0.9890\n",
      "Epoch 97/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0744 - accuracy: 0.9781 - val_loss: 0.0506 - val_accuracy: 0.9886\n",
      "Epoch 98/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0754 - accuracy: 0.9758 - val_loss: 0.0510 - val_accuracy: 0.9878\n",
      "Epoch 99/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0754 - accuracy: 0.9779 - val_loss: 0.0504 - val_accuracy: 0.9886\n",
      "Epoch 100/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0731 - accuracy: 0.9771 - val_loss: 0.0498 - val_accuracy: 0.9874\n"
     ]
    }
   ],
   "source": [
    "history_4, model_4 = fit_model(model_4, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"100_Dense_64-DO_0.3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 299, 299, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 149, 149, 32  864         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 149, 149, 32  96         ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 149, 149, 32  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 147, 147, 32  9216        ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 147, 147, 32  96         ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 147, 147, 32  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 147, 147, 64  18432       ['activation_1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 147, 147, 64  192        ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 147, 147, 64  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 73, 73, 64)   0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 73, 73, 80)   5120        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 73, 73, 80)  240         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 73, 73, 80)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 71, 71, 192)  138240      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 71, 71, 192)  576        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 71, 71, 192)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0          ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 35, 35, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 35, 35, 96)   55296       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 35, 35, 48)  144         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 35, 35, 96)  288         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 35, 35, 48)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 35, 35, 96)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 35, 35, 192)  0          ['max_pooling2d_1[0][0]']        \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 35, 35, 64)   76800       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 35, 35, 32)   6144        ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 35, 35, 96)  288         ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 35, 35, 32)  96          ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 35, 35, 256)  0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_7[0][0]',           \n",
      "                                                                  'activation_10[0][0]',          \n",
      "                                                                  'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 35, 35, 64)  192         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 35, 35, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 35, 35, 48)  144         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 35, 35, 96)  288         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 35, 35, 256)  0          ['mixed0[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 35, 35, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 35, 35, 64)  192         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 35, 35, 64)  192         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 35, 35, 96)  288         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 35, 35, 64)  192         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 35, 35, 288)  0           ['activation_12[0][0]',          \n",
      "                                                                  'activation_14[0][0]',          \n",
      "                                                                  'activation_17[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 35, 35, 64)  192         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 35, 35, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 35, 35, 48)  144         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 35, 35, 96)  288         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 35, 35, 288)  0          ['mixed1[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 35, 35, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 35, 35, 64)  192         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 35, 35, 64)  192         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 35, 35, 96)  288         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 35, 35, 64)  192         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 35, 35, 288)  0           ['activation_19[0][0]',          \n",
      "                                                                  'activation_21[0][0]',          \n",
      "                                                                  'activation_24[0][0]',          \n",
      "                                                                  'activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 35, 35, 64)  192         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 35, 35, 96)  288         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 17, 17, 384)  995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 17, 17, 96)   82944       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 17, 17, 384)  1152       ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 17, 17, 96)  288         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 17, 17, 384)  0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 17, 17, 96)   0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0          ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 17, 17, 768)  0           ['activation_26[0][0]',          \n",
      "                                                                  'activation_29[0][0]',          \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 17, 17, 128)  384        ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 17, 17, 128)  384        ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 17, 17, 128)  384        ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 17, 17, 128)  384        ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 17, 17, 128)  384        ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 17, 17, 128)  384        ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 17, 17, 768)  0          ['mixed3[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 17, 17, 192)  576        ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 17, 17, 192)  576        ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 17, 17, 192)  576        ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 17, 17, 192)  576        ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 17, 17, 768)  0           ['activation_30[0][0]',          \n",
      "                                                                  'activation_33[0][0]',          \n",
      "                                                                  'activation_38[0][0]',          \n",
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 17, 17, 160)  480        ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 17, 17, 160)  480        ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 17, 17, 160)  480        ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 17, 17, 160)  480        ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 17, 17, 160)  480        ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 17, 17, 160)  480        ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, 17, 17, 768)  0          ['mixed4[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 17, 17, 192)  576        ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 17, 17, 192)  576        ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 17, 17, 192)  576        ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 17, 17, 192)  576        ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 17, 17, 768)  0           ['activation_40[0][0]',          \n",
      "                                                                  'activation_43[0][0]',          \n",
      "                                                                  'activation_48[0][0]',          \n",
      "                                                                  'activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 17, 17, 160)  480        ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 17, 17, 160)  480        ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 17, 17, 160)  480        ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 17, 17, 160)  480        ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 17, 17, 160)  480        ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 17, 17, 160)  480        ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, 17, 17, 768)  0          ['mixed5[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_5[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 17, 17, 192)  576        ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 17, 17, 192)  576        ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 17, 17, 192)  576        ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 17, 17, 192)  576        ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 17, 17, 768)  0           ['activation_50[0][0]',          \n",
      "                                                                  'activation_53[0][0]',          \n",
      "                                                                  'activation_58[0][0]',          \n",
      "                                                                  'activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 17, 17, 192)  576        ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 17, 17, 192)  576        ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 17, 17, 192)  576        ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 17, 17, 192)  576        ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 17, 17, 192)  576        ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 17, 17, 192)  576        ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (AveragePo  (None, 17, 17, 768)  0          ['mixed6[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_6[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 17, 17, 192)  576        ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 17, 17, 192)  576        ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 17, 17, 192)  576        ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 17, 17, 192)  576        ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 17, 17, 768)  0           ['activation_60[0][0]',          \n",
      "                                                                  'activation_63[0][0]',          \n",
      "                                                                  'activation_68[0][0]',          \n",
      "                                                                  'activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 17, 17, 192)  576        ['conv2d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_72[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 17, 17, 192)  576        ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_73[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 17, 17, 192)  576        ['conv2d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 17, 17, 192)  576        ['conv2d_74[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 8, 8, 320)    552960      ['activation_70[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 8, 8, 192)    331776      ['activation_74[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 8, 8, 320)   960         ['conv2d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 8, 8, 192)   576         ['conv2d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)   0           ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 8, 8, 1280)   0           ['activation_71[0][0]',          \n",
      "                                                                  'activation_75[0][0]',          \n",
      "                                                                  'max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 8, 8, 448)    573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_80[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 8, 8, 384)    491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_80[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_7 (AveragePo  (None, 8, 8, 1280)  0           ['mixed8[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 8, 8, 320)    409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_78[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_79[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_82[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_83[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 8, 8, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 8, 8, 320)   960         ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 8, 8, 192)   576         ['conv2d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 8, 8, 768)    0           ['activation_78[0][0]',          \n",
      "                                                                  'activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 8, 8, 768)    0           ['activation_82[0][0]',          \n",
      "                                                                  'activation_83[0][0]']          \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, 8, 8, 2048)   0           ['activation_76[0][0]',          \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate[0][0]',            \n",
      "                                                                  'activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 8, 8, 448)    917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 8, 8, 384)    786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_89[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_86[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_8 (AveragePo  (None, 8, 8, 2048)  0           ['mixed9[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 8, 8, 320)    655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_88[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_91[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_92[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 8, 8, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 8, 8, 320)   960         ['conv2d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 8, 8, 192)   576         ['conv2d_93[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 8, 8, 768)    0           ['activation_87[0][0]',          \n",
      "                                                                  'activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 8, 8, 768)    0           ['activation_91[0][0]',          \n",
      "                                                                  'activation_92[0][0]']          \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 8, 8, 2048)   0           ['activation_85[0][0]',          \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_1[0][0]',          \n",
      "                                                                  'activation_93[0][0]']          \n",
      "                                                                                                  \n",
      " global_average_pooling2d_7 (Gl  (None, 2048)        0           ['mixed10[0][0]']                \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 64)           131136      ['global_average_pooling2d_7[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 64)           0           ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 4)            260         ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,934,180\n",
      "Trainable params: 131,396\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "build_5 = build_model(64, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "223/223 [==============================] - 60s 244ms/step - loss: 0.7651 - accuracy: 0.7046 - val_loss: 0.4023 - val_accuracy: 0.8761\n",
      "Epoch 2/100\n",
      "223/223 [==============================] - 53s 239ms/step - loss: 0.3988 - accuracy: 0.8584 - val_loss: 0.2692 - val_accuracy: 0.9204\n",
      "Epoch 3/100\n",
      "223/223 [==============================] - 84s 377ms/step - loss: 0.2951 - accuracy: 0.9004 - val_loss: 0.2012 - val_accuracy: 0.9435\n",
      "Epoch 4/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.2287 - accuracy: 0.9244 - val_loss: 0.1610 - val_accuracy: 0.9545\n",
      "Epoch 5/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1843 - accuracy: 0.9432 - val_loss: 0.1358 - val_accuracy: 0.9659\n",
      "Epoch 6/100\n",
      "223/223 [==============================] - 55s 244ms/step - loss: 0.1609 - accuracy: 0.9487 - val_loss: 0.1170 - val_accuracy: 0.9713\n",
      "Epoch 7/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.1323 - accuracy: 0.9612 - val_loss: 0.1028 - val_accuracy: 0.9760\n",
      "Epoch 8/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.1209 - accuracy: 0.9680 - val_loss: 0.0927 - val_accuracy: 0.9794\n",
      "Epoch 9/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.1035 - accuracy: 0.9753 - val_loss: 0.0835 - val_accuracy: 0.9789\n",
      "Epoch 10/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0919 - accuracy: 0.9778 - val_loss: 0.0716 - val_accuracy: 0.9836\n",
      "Epoch 11/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0839 - accuracy: 0.9784 - val_loss: 0.0665 - val_accuracy: 0.9861\n",
      "Epoch 12/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0754 - accuracy: 0.9815 - val_loss: 0.0612 - val_accuracy: 0.9861\n",
      "Epoch 13/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0648 - accuracy: 0.9860 - val_loss: 0.0548 - val_accuracy: 0.9895\n",
      "Epoch 14/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0593 - accuracy: 0.9882 - val_loss: 0.0506 - val_accuracy: 0.9882\n",
      "Epoch 15/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0507 - accuracy: 0.9904 - val_loss: 0.0495 - val_accuracy: 0.9903\n",
      "Epoch 16/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0478 - accuracy: 0.9906 - val_loss: 0.0431 - val_accuracy: 0.9907\n",
      "Epoch 17/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0447 - accuracy: 0.9899 - val_loss: 0.0493 - val_accuracy: 0.9882\n",
      "Epoch 18/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0412 - accuracy: 0.9916 - val_loss: 0.0387 - val_accuracy: 0.9912\n",
      "Epoch 19/100\n",
      "223/223 [==============================] - 55s 244ms/step - loss: 0.0360 - accuracy: 0.9923 - val_loss: 0.0404 - val_accuracy: 0.9903\n",
      "Epoch 20/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0348 - accuracy: 0.9927 - val_loss: 0.0348 - val_accuracy: 0.9907\n",
      "Epoch 21/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0305 - accuracy: 0.9942 - val_loss: 0.0330 - val_accuracy: 0.9912\n",
      "Epoch 22/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0271 - accuracy: 0.9949 - val_loss: 0.0312 - val_accuracy: 0.9916\n",
      "Epoch 23/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0280 - accuracy: 0.9944 - val_loss: 0.0339 - val_accuracy: 0.9916\n",
      "Epoch 24/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0256 - accuracy: 0.9958 - val_loss: 0.0329 - val_accuracy: 0.9899\n",
      "Epoch 25/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0230 - accuracy: 0.9956 - val_loss: 0.0273 - val_accuracy: 0.9937\n",
      "Epoch 26/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0198 - accuracy: 0.9965 - val_loss: 0.0287 - val_accuracy: 0.9928\n",
      "Epoch 27/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0214 - accuracy: 0.9962 - val_loss: 0.0295 - val_accuracy: 0.9928\n",
      "Epoch 28/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0173 - accuracy: 0.9980 - val_loss: 0.0244 - val_accuracy: 0.9945\n",
      "Epoch 29/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0154 - accuracy: 0.9986 - val_loss: 0.0249 - val_accuracy: 0.9933\n",
      "Epoch 30/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 0.0158 - accuracy: 0.9982 - val_loss: 0.0231 - val_accuracy: 0.9920\n",
      "Epoch 31/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0151 - accuracy: 0.9976 - val_loss: 0.0232 - val_accuracy: 0.9933\n",
      "Epoch 32/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 0.0135 - accuracy: 0.9982 - val_loss: 0.0213 - val_accuracy: 0.9949\n",
      "Epoch 33/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0123 - accuracy: 0.9987 - val_loss: 0.0216 - val_accuracy: 0.9924\n",
      "Epoch 34/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0124 - accuracy: 0.9980 - val_loss: 0.0205 - val_accuracy: 0.9941\n",
      "Epoch 35/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0114 - accuracy: 0.9985 - val_loss: 0.0212 - val_accuracy: 0.9941\n",
      "Epoch 36/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0103 - accuracy: 0.9987 - val_loss: 0.0207 - val_accuracy: 0.9945\n",
      "Epoch 37/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 0.0091 - accuracy: 0.9993 - val_loss: 0.0214 - val_accuracy: 0.9937\n",
      "Epoch 38/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0112 - accuracy: 0.9980 - val_loss: 0.0201 - val_accuracy: 0.9937\n",
      "Epoch 39/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0078 - accuracy: 0.9996 - val_loss: 0.0215 - val_accuracy: 0.9933\n",
      "Epoch 40/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0094 - accuracy: 0.9983 - val_loss: 0.0204 - val_accuracy: 0.9928\n",
      "Epoch 41/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0083 - accuracy: 0.9996 - val_loss: 0.0237 - val_accuracy: 0.9928\n",
      "Epoch 42/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0067 - accuracy: 0.9997 - val_loss: 0.0181 - val_accuracy: 0.9941\n",
      "Epoch 43/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0069 - accuracy: 0.9990 - val_loss: 0.0184 - val_accuracy: 0.9945\n",
      "Epoch 44/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0077 - accuracy: 0.9986 - val_loss: 0.0177 - val_accuracy: 0.9945\n",
      "Epoch 45/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0068 - accuracy: 0.9992 - val_loss: 0.0181 - val_accuracy: 0.9945\n",
      "Epoch 46/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 0.0055 - accuracy: 0.9997 - val_loss: 0.0180 - val_accuracy: 0.9954\n",
      "Epoch 47/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0053 - accuracy: 0.9999 - val_loss: 0.0171 - val_accuracy: 0.9928\n",
      "Epoch 48/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0040 - accuracy: 0.9999 - val_loss: 0.0167 - val_accuracy: 0.9945\n",
      "Epoch 49/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0051 - accuracy: 0.9993 - val_loss: 0.0187 - val_accuracy: 0.9945\n",
      "Epoch 50/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0044 - accuracy: 0.9999 - val_loss: 0.0172 - val_accuracy: 0.9954\n",
      "Epoch 51/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0040 - accuracy: 0.9997 - val_loss: 0.0176 - val_accuracy: 0.9949\n",
      "Epoch 52/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0037 - accuracy: 0.9999 - val_loss: 0.0180 - val_accuracy: 0.9945\n",
      "Epoch 53/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.0225 - val_accuracy: 0.9928\n",
      "Epoch 54/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0033 - accuracy: 0.9999 - val_loss: 0.0173 - val_accuracy: 0.9949\n",
      "Epoch 55/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0038 - accuracy: 0.9997 - val_loss: 0.0195 - val_accuracy: 0.9945\n",
      "Epoch 56/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0030 - accuracy: 0.9997 - val_loss: 0.0195 - val_accuracy: 0.9954\n",
      "Epoch 57/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 0.0169 - val_accuracy: 0.9945\n",
      "Epoch 58/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0029 - accuracy: 0.9997 - val_loss: 0.0171 - val_accuracy: 0.9945\n",
      "Epoch 59/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.0178 - val_accuracy: 0.9937\n",
      "Epoch 60/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0032 - accuracy: 0.9997 - val_loss: 0.0172 - val_accuracy: 0.9941\n",
      "Epoch 61/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.0180 - val_accuracy: 0.9949\n",
      "Epoch 62/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.0161 - val_accuracy: 0.9949\n",
      "Epoch 63/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 0.9945\n",
      "Epoch 64/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.0172 - val_accuracy: 0.9941\n",
      "Epoch 65/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0187 - val_accuracy: 0.9949\n",
      "Epoch 66/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.0201 - val_accuracy: 0.9945\n",
      "Epoch 67/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 0.0179 - val_accuracy: 0.9962\n",
      "Epoch 68/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 0.0170 - val_accuracy: 0.9949\n",
      "Epoch 69/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 0.9941\n",
      "Epoch 70/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.0182 - val_accuracy: 0.9954\n",
      "Epoch 71/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.0162 - val_accuracy: 0.9945\n",
      "Epoch 72/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0183 - val_accuracy: 0.9962\n",
      "Epoch 73/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.0174 - val_accuracy: 0.9962\n",
      "Epoch 74/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.0163 - val_accuracy: 0.9949\n",
      "Epoch 75/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.0181 - val_accuracy: 0.9949\n",
      "Epoch 76/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9958\n",
      "Epoch 77/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0166 - val_accuracy: 0.9962\n",
      "Epoch 78/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0175 - val_accuracy: 0.9954\n",
      "Epoch 79/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9954\n",
      "Epoch 80/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 0.9949\n",
      "Epoch 81/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 0.9958\n",
      "Epoch 82/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 0.9941\n",
      "Epoch 83/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.0171 - val_accuracy: 0.9954\n",
      "Epoch 84/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.0173 - val_accuracy: 0.9954\n",
      "Epoch 85/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0175 - val_accuracy: 0.9928\n",
      "Epoch 86/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 0.9954\n",
      "Epoch 87/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 7.9730e-04 - accuracy: 1.0000 - val_loss: 0.0202 - val_accuracy: 0.9949\n",
      "Epoch 88/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0192 - val_accuracy: 0.9941\n",
      "Epoch 89/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 9.7031e-04 - accuracy: 1.0000 - val_loss: 0.0163 - val_accuracy: 0.9958\n",
      "Epoch 90/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 9.6524e-04 - accuracy: 1.0000 - val_loss: 0.0163 - val_accuracy: 0.9958\n",
      "Epoch 91/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9962\n",
      "Epoch 92/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0155 - val_accuracy: 0.9954\n",
      "Epoch 93/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0158 - val_accuracy: 0.9945\n",
      "Epoch 94/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 9.1174e-04 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 0.9966\n",
      "Epoch 95/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 7.2665e-04 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 0.9941\n",
      "Epoch 96/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.0182 - val_accuracy: 0.9954\n",
      "Epoch 97/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 8.7311e-04 - accuracy: 1.0000 - val_loss: 0.0202 - val_accuracy: 0.9945\n",
      "Epoch 98/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0174 - val_accuracy: 0.9945\n",
      "Epoch 99/100\n",
      "223/223 [==============================] - 54s 242ms/step - loss: 8.3054e-04 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 0.9954\n",
      "Epoch 100/100\n",
      "223/223 [==============================] - 54s 241ms/step - loss: 5.8872e-04 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 0.9958\n"
     ]
    }
   ],
   "source": [
    "history_5, model_5 = fit_model(build_5, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"100_Dense_64-DO_0.4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 299, 299, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 149, 149, 32  864         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 149, 149, 32  96         ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 149, 149, 32  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 147, 147, 32  9216        ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 147, 147, 32  96         ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 147, 147, 32  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 147, 147, 64  18432       ['activation_1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 147, 147, 64  192        ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 147, 147, 64  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 73, 73, 64)   0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 73, 73, 80)   5120        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 73, 73, 80)  240         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 73, 73, 80)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 71, 71, 192)  138240      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 71, 71, 192)  576        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 71, 71, 192)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0          ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 35, 35, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 35, 35, 96)   55296       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 35, 35, 48)  144         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 35, 35, 96)  288         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 35, 35, 48)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 35, 35, 96)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 35, 35, 192)  0          ['max_pooling2d_1[0][0]']        \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 35, 35, 64)   76800       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 35, 35, 32)   6144        ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 35, 35, 96)  288         ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 35, 35, 32)  96          ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 35, 35, 256)  0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_7[0][0]',           \n",
      "                                                                  'activation_10[0][0]',          \n",
      "                                                                  'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 35, 35, 64)  192         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 35, 35, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 35, 35, 48)  144         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 35, 35, 96)  288         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 35, 35, 256)  0          ['mixed0[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 35, 35, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 35, 35, 64)  192         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 35, 35, 64)  192         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 35, 35, 96)  288         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 35, 35, 64)  192         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 35, 35, 288)  0           ['activation_12[0][0]',          \n",
      "                                                                  'activation_14[0][0]',          \n",
      "                                                                  'activation_17[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 35, 35, 64)  192         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 35, 35, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 35, 35, 48)  144         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 35, 35, 96)  288         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 35, 35, 288)  0          ['mixed1[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 35, 35, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 35, 35, 64)  192         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 35, 35, 64)  192         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 35, 35, 96)  288         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 35, 35, 64)  192         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 35, 35, 288)  0           ['activation_19[0][0]',          \n",
      "                                                                  'activation_21[0][0]',          \n",
      "                                                                  'activation_24[0][0]',          \n",
      "                                                                  'activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 35, 35, 64)  192         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 35, 35, 96)  288         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 17, 17, 384)  995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 17, 17, 96)   82944       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 17, 17, 384)  1152       ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 17, 17, 96)  288         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 17, 17, 384)  0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 17, 17, 96)   0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0          ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 17, 17, 768)  0           ['activation_26[0][0]',          \n",
      "                                                                  'activation_29[0][0]',          \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 17, 17, 128)  384        ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 17, 17, 128)  384        ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 17, 17, 128)  384        ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 17, 17, 128)  384        ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 17, 17, 128)  384        ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 17, 17, 128)  384        ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 17, 17, 768)  0          ['mixed3[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 17, 17, 192)  576        ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 17, 17, 192)  576        ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 17, 17, 192)  576        ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 17, 17, 192)  576        ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 17, 17, 768)  0           ['activation_30[0][0]',          \n",
      "                                                                  'activation_33[0][0]',          \n",
      "                                                                  'activation_38[0][0]',          \n",
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 17, 17, 160)  480        ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 17, 17, 160)  480        ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 17, 17, 160)  480        ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 17, 17, 160)  480        ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 17, 17, 160)  480        ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 17, 17, 160)  480        ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, 17, 17, 768)  0          ['mixed4[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 17, 17, 192)  576        ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 17, 17, 192)  576        ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 17, 17, 192)  576        ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 17, 17, 192)  576        ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 17, 17, 768)  0           ['activation_40[0][0]',          \n",
      "                                                                  'activation_43[0][0]',          \n",
      "                                                                  'activation_48[0][0]',          \n",
      "                                                                  'activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 17, 17, 160)  480        ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 17, 17, 160)  480        ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 17, 17, 160)  480        ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 17, 17, 160)  480        ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 17, 17, 160)  480        ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 17, 17, 160)  480        ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, 17, 17, 768)  0          ['mixed5[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_5[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 17, 17, 192)  576        ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 17, 17, 192)  576        ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 17, 17, 192)  576        ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 17, 17, 192)  576        ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 17, 17, 768)  0           ['activation_50[0][0]',          \n",
      "                                                                  'activation_53[0][0]',          \n",
      "                                                                  'activation_58[0][0]',          \n",
      "                                                                  'activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 17, 17, 192)  576        ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 17, 17, 192)  576        ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 17, 17, 192)  576        ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 17, 17, 192)  576        ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 17, 17, 192)  576        ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 17, 17, 192)  576        ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (AveragePo  (None, 17, 17, 768)  0          ['mixed6[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_6[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 17, 17, 192)  576        ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 17, 17, 192)  576        ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 17, 17, 192)  576        ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 17, 17, 192)  576        ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 17, 17, 768)  0           ['activation_60[0][0]',          \n",
      "                                                                  'activation_63[0][0]',          \n",
      "                                                                  'activation_68[0][0]',          \n",
      "                                                                  'activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 17, 17, 192)  576        ['conv2d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_72[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 17, 17, 192)  576        ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_73[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 17, 17, 192)  576        ['conv2d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 17, 17, 192)  576        ['conv2d_74[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 8, 8, 320)    552960      ['activation_70[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 8, 8, 192)    331776      ['activation_74[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 8, 8, 320)   960         ['conv2d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 8, 8, 192)   576         ['conv2d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)   0           ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 8, 8, 1280)   0           ['activation_71[0][0]',          \n",
      "                                                                  'activation_75[0][0]',          \n",
      "                                                                  'max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 8, 8, 448)    573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_80[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 8, 8, 384)    491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_80[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_7 (AveragePo  (None, 8, 8, 1280)  0           ['mixed8[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 8, 8, 320)    409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_78[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_79[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_82[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_83[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 8, 8, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 8, 8, 320)   960         ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 8, 8, 192)   576         ['conv2d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 8, 8, 768)    0           ['activation_78[0][0]',          \n",
      "                                                                  'activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 8, 8, 768)    0           ['activation_82[0][0]',          \n",
      "                                                                  'activation_83[0][0]']          \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, 8, 8, 2048)   0           ['activation_76[0][0]',          \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate[0][0]',            \n",
      "                                                                  'activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 8, 8, 448)    917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 8, 8, 384)    786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_89[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_86[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_8 (AveragePo  (None, 8, 8, 2048)  0           ['mixed9[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 8, 8, 320)    655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_88[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_91[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_92[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 8, 8, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 8, 8, 320)   960         ['conv2d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 8, 8, 192)   576         ['conv2d_93[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 8, 8, 768)    0           ['activation_87[0][0]',          \n",
      "                                                                  'activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 8, 8, 768)    0           ['activation_91[0][0]',          \n",
      "                                                                  'activation_92[0][0]']          \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 8, 8, 2048)   0           ['activation_85[0][0]',          \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_1[0][0]',          \n",
      "                                                                  'activation_93[0][0]']          \n",
      "                                                                                                  \n",
      " global_average_pooling2d_8 (Gl  (None, 2048)        0           ['mixed10[0][0]']                \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 64)           131136      ['global_average_pooling2d_8[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 64)           0           ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 4)            260         ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,934,180\n",
      "Trainable params: 131,396\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "build_6 = build_model(64, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "223/223 [==============================] - 60s 251ms/step - loss: 0.7982 - accuracy: 0.6897 - val_loss: 0.4105 - val_accuracy: 0.8761\n",
      "Epoch 2/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.4182 - accuracy: 0.8556 - val_loss: 0.2738 - val_accuracy: 0.9107\n",
      "Epoch 3/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.3137 - accuracy: 0.8960 - val_loss: 0.2061 - val_accuracy: 0.9440\n",
      "Epoch 4/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.2509 - accuracy: 0.9201 - val_loss: 0.1632 - val_accuracy: 0.9545\n",
      "Epoch 5/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.2175 - accuracy: 0.9292 - val_loss: 0.1422 - val_accuracy: 0.9642\n",
      "Epoch 6/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1815 - accuracy: 0.9444 - val_loss: 0.1206 - val_accuracy: 0.9684\n",
      "Epoch 7/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1576 - accuracy: 0.9529 - val_loss: 0.1054 - val_accuracy: 0.9730\n",
      "Epoch 8/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1425 - accuracy: 0.9573 - val_loss: 0.0952 - val_accuracy: 0.9760\n",
      "Epoch 9/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1302 - accuracy: 0.9628 - val_loss: 0.0875 - val_accuracy: 0.9785\n",
      "Epoch 10/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.1103 - accuracy: 0.9688 - val_loss: 0.0767 - val_accuracy: 0.9815\n",
      "Epoch 11/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1013 - accuracy: 0.9743 - val_loss: 0.0699 - val_accuracy: 0.9836\n",
      "Epoch 12/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0909 - accuracy: 0.9753 - val_loss: 0.0646 - val_accuracy: 0.9827\n",
      "Epoch 13/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0819 - accuracy: 0.9774 - val_loss: 0.0608 - val_accuracy: 0.9836\n",
      "Epoch 14/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0710 - accuracy: 0.9830 - val_loss: 0.0542 - val_accuracy: 0.9869\n",
      "Epoch 15/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0702 - accuracy: 0.9820 - val_loss: 0.0502 - val_accuracy: 0.9882\n",
      "Epoch 16/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0660 - accuracy: 0.9838 - val_loss: 0.0471 - val_accuracy: 0.9895\n",
      "Epoch 17/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0579 - accuracy: 0.9851 - val_loss: 0.0443 - val_accuracy: 0.9899\n",
      "Epoch 18/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0542 - accuracy: 0.9862 - val_loss: 0.0408 - val_accuracy: 0.9899\n",
      "Epoch 19/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0495 - accuracy: 0.9890 - val_loss: 0.0386 - val_accuracy: 0.9899\n",
      "Epoch 20/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0431 - accuracy: 0.9902 - val_loss: 0.0365 - val_accuracy: 0.9912\n",
      "Epoch 21/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0408 - accuracy: 0.9910 - val_loss: 0.0341 - val_accuracy: 0.9903\n",
      "Epoch 22/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0395 - accuracy: 0.9917 - val_loss: 0.0362 - val_accuracy: 0.9878\n",
      "Epoch 23/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0365 - accuracy: 0.9928 - val_loss: 0.0319 - val_accuracy: 0.9928\n",
      "Epoch 24/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0353 - accuracy: 0.9923 - val_loss: 0.0306 - val_accuracy: 0.9907\n",
      "Epoch 25/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0312 - accuracy: 0.9945 - val_loss: 0.0294 - val_accuracy: 0.9941\n",
      "Epoch 26/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0274 - accuracy: 0.9955 - val_loss: 0.0282 - val_accuracy: 0.9924\n",
      "Epoch 27/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0279 - accuracy: 0.9948 - val_loss: 0.0298 - val_accuracy: 0.9903\n",
      "Epoch 28/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0277 - accuracy: 0.9934 - val_loss: 0.0269 - val_accuracy: 0.9916\n",
      "Epoch 29/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0250 - accuracy: 0.9954 - val_loss: 0.0273 - val_accuracy: 0.9903\n",
      "Epoch 30/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0211 - accuracy: 0.9962 - val_loss: 0.0309 - val_accuracy: 0.9899\n",
      "Epoch 31/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0217 - accuracy: 0.9961 - val_loss: 0.0249 - val_accuracy: 0.9933\n",
      "Epoch 32/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0210 - accuracy: 0.9961 - val_loss: 0.0269 - val_accuracy: 0.9920\n",
      "Epoch 33/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0182 - accuracy: 0.9979 - val_loss: 0.0227 - val_accuracy: 0.9937\n",
      "Epoch 34/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0183 - accuracy: 0.9965 - val_loss: 0.0216 - val_accuracy: 0.9949\n",
      "Epoch 35/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0167 - accuracy: 0.9966 - val_loss: 0.0213 - val_accuracy: 0.9945\n",
      "Epoch 36/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0153 - accuracy: 0.9979 - val_loss: 0.0231 - val_accuracy: 0.9924\n",
      "Epoch 37/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0141 - accuracy: 0.9982 - val_loss: 0.0212 - val_accuracy: 0.9945\n",
      "Epoch 38/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0150 - accuracy: 0.9972 - val_loss: 0.0211 - val_accuracy: 0.9941\n",
      "Epoch 39/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0143 - accuracy: 0.9969 - val_loss: 0.0196 - val_accuracy: 0.9933\n",
      "Epoch 40/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0119 - accuracy: 0.9987 - val_loss: 0.0201 - val_accuracy: 0.9937\n",
      "Epoch 41/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0122 - accuracy: 0.9985 - val_loss: 0.0207 - val_accuracy: 0.9949\n",
      "Epoch 42/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0121 - accuracy: 0.9980 - val_loss: 0.0192 - val_accuracy: 0.9937\n",
      "Epoch 43/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0102 - accuracy: 0.9985 - val_loss: 0.0206 - val_accuracy: 0.9928\n",
      "Epoch 44/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0098 - accuracy: 0.9990 - val_loss: 0.0180 - val_accuracy: 0.9937\n",
      "Epoch 45/100\n",
      "223/223 [==============================] - 55s 244ms/step - loss: 0.0092 - accuracy: 0.9990 - val_loss: 0.0182 - val_accuracy: 0.9941\n",
      "Epoch 46/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0085 - accuracy: 0.9989 - val_loss: 0.0189 - val_accuracy: 0.9937\n",
      "Epoch 47/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0082 - accuracy: 0.9990 - val_loss: 0.0179 - val_accuracy: 0.9941\n",
      "Epoch 48/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0080 - accuracy: 0.9990 - val_loss: 0.0196 - val_accuracy: 0.9933\n",
      "Epoch 49/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0071 - accuracy: 0.9997 - val_loss: 0.0226 - val_accuracy: 0.9912\n",
      "Epoch 50/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0079 - accuracy: 0.9987 - val_loss: 0.0183 - val_accuracy: 0.9945\n",
      "Epoch 51/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0076 - accuracy: 0.9990 - val_loss: 0.0278 - val_accuracy: 0.9903\n",
      "Epoch 52/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0073 - accuracy: 0.9993 - val_loss: 0.0199 - val_accuracy: 0.9941\n",
      "Epoch 53/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0054 - accuracy: 0.9996 - val_loss: 0.0173 - val_accuracy: 0.9945\n",
      "Epoch 54/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0059 - accuracy: 0.9999 - val_loss: 0.0181 - val_accuracy: 0.9941\n",
      "Epoch 55/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0051 - accuracy: 0.9997 - val_loss: 0.0181 - val_accuracy: 0.9933\n",
      "Epoch 56/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0057 - accuracy: 0.9997 - val_loss: 0.0217 - val_accuracy: 0.9924\n",
      "Epoch 57/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0053 - accuracy: 0.9997 - val_loss: 0.0229 - val_accuracy: 0.9924\n",
      "Epoch 58/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0056 - accuracy: 0.9997 - val_loss: 0.0175 - val_accuracy: 0.9933\n",
      "Epoch 59/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0057 - accuracy: 0.9992 - val_loss: 0.0168 - val_accuracy: 0.9945\n",
      "Epoch 60/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.0178 - val_accuracy: 0.9924\n",
      "Epoch 61/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0055 - accuracy: 0.9993 - val_loss: 0.0170 - val_accuracy: 0.9937\n",
      "Epoch 62/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.0181 - val_accuracy: 0.9941\n",
      "Epoch 63/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0039 - accuracy: 0.9996 - val_loss: 0.0219 - val_accuracy: 0.9924\n",
      "Epoch 64/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0035 - accuracy: 0.9999 - val_loss: 0.0183 - val_accuracy: 0.9933\n",
      "Epoch 65/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0036 - accuracy: 0.9999 - val_loss: 0.0183 - val_accuracy: 0.9928\n",
      "Epoch 66/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0045 - accuracy: 0.9993 - val_loss: 0.0202 - val_accuracy: 0.9933\n",
      "Epoch 67/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 0.0174 - val_accuracy: 0.9954\n",
      "Epoch 68/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0180 - val_accuracy: 0.9941\n",
      "Epoch 69/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.0189 - val_accuracy: 0.9941\n",
      "Epoch 70/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0035 - accuracy: 0.9999 - val_loss: 0.0194 - val_accuracy: 0.9933\n",
      "Epoch 71/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0030 - accuracy: 0.9999 - val_loss: 0.0163 - val_accuracy: 0.9937\n",
      "Epoch 72/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.0163 - val_accuracy: 0.9937\n",
      "Epoch 73/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.0205 - val_accuracy: 0.9916\n",
      "Epoch 74/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0030 - accuracy: 0.9997 - val_loss: 0.0193 - val_accuracy: 0.9928\n",
      "Epoch 75/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.0166 - val_accuracy: 0.9949\n",
      "Epoch 76/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.0206 - val_accuracy: 0.9937\n",
      "Epoch 77/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.0173 - val_accuracy: 0.9937\n",
      "Epoch 78/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.0151 - val_accuracy: 0.9945\n",
      "Epoch 79/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0155 - val_accuracy: 0.9949\n",
      "Epoch 80/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 0.0191 - val_accuracy: 0.9933\n",
      "Epoch 81/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.0151 - val_accuracy: 0.9945\n",
      "Epoch 82/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 0.9937\n",
      "Epoch 83/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 0.9949\n",
      "Epoch 84/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0030 - accuracy: 0.9997 - val_loss: 0.0185 - val_accuracy: 0.9937\n",
      "Epoch 85/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.0197 - val_accuracy: 0.9928\n",
      "Epoch 86/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0172 - val_accuracy: 0.9954\n",
      "Epoch 87/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.0185 - val_accuracy: 0.9949\n",
      "Epoch 88/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.0197 - val_accuracy: 0.9928\n",
      "Epoch 89/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.0155 - val_accuracy: 0.9945\n",
      "Epoch 90/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 0.0208 - val_accuracy: 0.9937\n",
      "Epoch 91/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0163 - val_accuracy: 0.9954\n",
      "Epoch 92/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9954\n",
      "Epoch 93/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 0.9958\n",
      "Epoch 94/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0213 - val_accuracy: 0.9920\n",
      "Epoch 95/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 0.9941\n",
      "Epoch 96/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.0164 - val_accuracy: 0.9933\n",
      "Epoch 97/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 0.9933\n",
      "Epoch 98/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 0.9924\n",
      "Epoch 99/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0252 - val_accuracy: 0.9928\n",
      "Epoch 100/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0163 - val_accuracy: 0.9945\n"
     ]
    }
   ],
   "source": [
    "history_6, model_6 = fit_model(build_6, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"100_Dense_128-DO_0.4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 299, 299, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 149, 149, 32  864         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 149, 149, 32  96         ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 149, 149, 32  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 147, 147, 32  9216        ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 147, 147, 32  96         ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 147, 147, 32  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 147, 147, 64  18432       ['activation_1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 147, 147, 64  192        ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 147, 147, 64  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 73, 73, 64)   0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 73, 73, 80)   5120        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 73, 73, 80)  240         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 73, 73, 80)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 71, 71, 192)  138240      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 71, 71, 192)  576        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 71, 71, 192)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0          ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 35, 35, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 35, 35, 96)   55296       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 35, 35, 48)  144         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 35, 35, 96)  288         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 35, 35, 48)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 35, 35, 96)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 35, 35, 192)  0          ['max_pooling2d_1[0][0]']        \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 35, 35, 64)   76800       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 35, 35, 32)   6144        ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 35, 35, 96)  288         ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 35, 35, 32)  96          ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 35, 35, 256)  0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_7[0][0]',           \n",
      "                                                                  'activation_10[0][0]',          \n",
      "                                                                  'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 35, 35, 64)  192         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 35, 35, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 35, 35, 48)  144         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 35, 35, 96)  288         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 35, 35, 256)  0          ['mixed0[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 35, 35, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 35, 35, 64)  192         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 35, 35, 64)  192         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 35, 35, 96)  288         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 35, 35, 64)  192         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 35, 35, 288)  0           ['activation_12[0][0]',          \n",
      "                                                                  'activation_14[0][0]',          \n",
      "                                                                  'activation_17[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 35, 35, 64)  192         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 35, 35, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 35, 35, 48)  144         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 35, 35, 96)  288         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 35, 35, 288)  0          ['mixed1[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 35, 35, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 35, 35, 64)  192         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 35, 35, 64)  192         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 35, 35, 96)  288         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 35, 35, 64)  192         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 35, 35, 288)  0           ['activation_19[0][0]',          \n",
      "                                                                  'activation_21[0][0]',          \n",
      "                                                                  'activation_24[0][0]',          \n",
      "                                                                  'activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 35, 35, 64)  192         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 35, 35, 96)  288         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 17, 17, 384)  995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 17, 17, 96)   82944       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 17, 17, 384)  1152       ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 17, 17, 96)  288         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 17, 17, 384)  0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 17, 17, 96)   0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0          ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 17, 17, 768)  0           ['activation_26[0][0]',          \n",
      "                                                                  'activation_29[0][0]',          \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 17, 17, 128)  384        ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 17, 17, 128)  384        ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 17, 17, 128)  384        ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 17, 17, 128)  384        ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 17, 17, 128)  384        ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 17, 17, 128)  384        ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 17, 17, 768)  0          ['mixed3[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 17, 17, 192)  576        ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 17, 17, 192)  576        ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 17, 17, 192)  576        ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 17, 17, 192)  576        ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 17, 17, 768)  0           ['activation_30[0][0]',          \n",
      "                                                                  'activation_33[0][0]',          \n",
      "                                                                  'activation_38[0][0]',          \n",
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 17, 17, 160)  480        ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 17, 17, 160)  480        ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 17, 17, 160)  480        ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 17, 17, 160)  480        ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 17, 17, 160)  480        ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 17, 17, 160)  480        ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, 17, 17, 768)  0          ['mixed4[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 17, 17, 192)  576        ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 17, 17, 192)  576        ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 17, 17, 192)  576        ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 17, 17, 192)  576        ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 17, 17, 768)  0           ['activation_40[0][0]',          \n",
      "                                                                  'activation_43[0][0]',          \n",
      "                                                                  'activation_48[0][0]',          \n",
      "                                                                  'activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 17, 17, 160)  480        ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 17, 17, 160)  480        ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 17, 17, 160)  480        ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 17, 17, 160)  480        ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 17, 17, 160)  480        ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 17, 17, 160)  480        ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, 17, 17, 768)  0          ['mixed5[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_5[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 17, 17, 192)  576        ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 17, 17, 192)  576        ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 17, 17, 192)  576        ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 17, 17, 192)  576        ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 17, 17, 768)  0           ['activation_50[0][0]',          \n",
      "                                                                  'activation_53[0][0]',          \n",
      "                                                                  'activation_58[0][0]',          \n",
      "                                                                  'activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 17, 17, 192)  576        ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 17, 17, 192)  576        ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 17, 17, 192)  576        ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 17, 17, 192)  576        ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 17, 17, 192)  576        ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 17, 17, 192)  576        ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (AveragePo  (None, 17, 17, 768)  0          ['mixed6[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_6[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 17, 17, 192)  576        ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 17, 17, 192)  576        ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 17, 17, 192)  576        ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 17, 17, 192)  576        ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 17, 17, 768)  0           ['activation_60[0][0]',          \n",
      "                                                                  'activation_63[0][0]',          \n",
      "                                                                  'activation_68[0][0]',          \n",
      "                                                                  'activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 17, 17, 192)  576        ['conv2d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_72[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 17, 17, 192)  576        ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_73[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 17, 17, 192)  576        ['conv2d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 17, 17, 192)  576        ['conv2d_74[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 8, 8, 320)    552960      ['activation_70[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 8, 8, 192)    331776      ['activation_74[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 8, 8, 320)   960         ['conv2d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 8, 8, 192)   576         ['conv2d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)   0           ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 8, 8, 1280)   0           ['activation_71[0][0]',          \n",
      "                                                                  'activation_75[0][0]',          \n",
      "                                                                  'max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 8, 8, 448)    573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_80[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 8, 8, 384)    491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_80[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_7 (AveragePo  (None, 8, 8, 1280)  0           ['mixed8[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 8, 8, 320)    409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_78[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_79[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_82[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_83[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 8, 8, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 8, 8, 320)   960         ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 8, 8, 192)   576         ['conv2d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 8, 8, 768)    0           ['activation_78[0][0]',          \n",
      "                                                                  'activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 8, 8, 768)    0           ['activation_82[0][0]',          \n",
      "                                                                  'activation_83[0][0]']          \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, 8, 8, 2048)   0           ['activation_76[0][0]',          \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate[0][0]',            \n",
      "                                                                  'activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 8, 8, 448)    917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 8, 8, 384)    786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_89[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_86[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_8 (AveragePo  (None, 8, 8, 2048)  0           ['mixed9[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 8, 8, 320)    655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_88[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_91[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_92[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 8, 8, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 8, 8, 320)   960         ['conv2d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 8, 8, 192)   576         ['conv2d_93[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 8, 8, 768)    0           ['activation_87[0][0]',          \n",
      "                                                                  'activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 8, 8, 768)    0           ['activation_91[0][0]',          \n",
      "                                                                  'activation_92[0][0]']          \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 8, 8, 2048)   0           ['activation_85[0][0]',          \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_1[0][0]',          \n",
      "                                                                  'activation_93[0][0]']          \n",
      "                                                                                                  \n",
      " global_average_pooling2d_9 (Gl  (None, 2048)        0           ['mixed10[0][0]']                \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 128)          262272      ['global_average_pooling2d_9[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 128)          0           ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 4)            516         ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 22,065,572\n",
      "Trainable params: 262,788\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "build_7 = build_model(128, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "223/223 [==============================] - 60s 251ms/step - loss: 0.6996 - accuracy: 0.7246 - val_loss: 0.3480 - val_accuracy: 0.8942\n",
      "Epoch 2/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.3442 - accuracy: 0.8845 - val_loss: 0.2272 - val_accuracy: 0.9393\n",
      "Epoch 3/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.2544 - accuracy: 0.9153 - val_loss: 0.1691 - val_accuracy: 0.9595\n",
      "Epoch 4/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1932 - accuracy: 0.9372 - val_loss: 0.1342 - val_accuracy: 0.9676\n",
      "Epoch 5/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.1609 - accuracy: 0.9504 - val_loss: 0.1146 - val_accuracy: 0.9701\n",
      "Epoch 6/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1313 - accuracy: 0.9629 - val_loss: 0.0934 - val_accuracy: 0.9777\n",
      "Epoch 7/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1121 - accuracy: 0.9681 - val_loss: 0.0828 - val_accuracy: 0.9827\n",
      "Epoch 8/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0935 - accuracy: 0.9764 - val_loss: 0.0729 - val_accuracy: 0.9815\n",
      "Epoch 9/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0838 - accuracy: 0.9779 - val_loss: 0.0638 - val_accuracy: 0.9861\n",
      "Epoch 10/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0723 - accuracy: 0.9817 - val_loss: 0.0598 - val_accuracy: 0.9890\n",
      "Epoch 11/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0631 - accuracy: 0.9852 - val_loss: 0.0531 - val_accuracy: 0.9903\n",
      "Epoch 12/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0585 - accuracy: 0.9854 - val_loss: 0.0477 - val_accuracy: 0.9903\n",
      "Epoch 13/100\n",
      "223/223 [==============================] - 55s 244ms/step - loss: 0.0526 - accuracy: 0.9878 - val_loss: 0.0433 - val_accuracy: 0.9912\n",
      "Epoch 14/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0446 - accuracy: 0.9893 - val_loss: 0.0414 - val_accuracy: 0.9933\n",
      "Epoch 15/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0400 - accuracy: 0.9917 - val_loss: 0.0353 - val_accuracy: 0.9928\n",
      "Epoch 16/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0352 - accuracy: 0.9935 - val_loss: 0.0386 - val_accuracy: 0.9920\n",
      "Epoch 17/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0326 - accuracy: 0.9937 - val_loss: 0.0318 - val_accuracy: 0.9937\n",
      "Epoch 18/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0285 - accuracy: 0.9947 - val_loss: 0.0312 - val_accuracy: 0.9907\n",
      "Epoch 19/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0252 - accuracy: 0.9962 - val_loss: 0.0293 - val_accuracy: 0.9920\n",
      "Epoch 20/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0252 - accuracy: 0.9952 - val_loss: 0.0258 - val_accuracy: 0.9949\n",
      "Epoch 21/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0205 - accuracy: 0.9979 - val_loss: 0.0250 - val_accuracy: 0.9941\n",
      "Epoch 22/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0187 - accuracy: 0.9972 - val_loss: 0.0256 - val_accuracy: 0.9928\n",
      "Epoch 23/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0174 - accuracy: 0.9978 - val_loss: 0.0236 - val_accuracy: 0.9933\n",
      "Epoch 24/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0173 - accuracy: 0.9973 - val_loss: 0.0227 - val_accuracy: 0.9941\n",
      "Epoch 25/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.0147 - accuracy: 0.9982 - val_loss: 0.0244 - val_accuracy: 0.9924\n",
      "Epoch 26/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.0138 - accuracy: 0.9978 - val_loss: 0.0253 - val_accuracy: 0.9928\n",
      "Epoch 27/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0125 - accuracy: 0.9986 - val_loss: 0.0204 - val_accuracy: 0.9949\n",
      "Epoch 28/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0119 - accuracy: 0.9993 - val_loss: 0.0218 - val_accuracy: 0.9941\n",
      "Epoch 29/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0099 - accuracy: 0.9987 - val_loss: 0.0196 - val_accuracy: 0.9949\n",
      "Epoch 30/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0089 - accuracy: 0.9997 - val_loss: 0.0192 - val_accuracy: 0.9941\n",
      "Epoch 31/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0086 - accuracy: 0.9992 - val_loss: 0.0197 - val_accuracy: 0.9945\n",
      "Epoch 32/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0086 - accuracy: 0.9993 - val_loss: 0.0176 - val_accuracy: 0.9945\n",
      "Epoch 33/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0073 - accuracy: 0.9993 - val_loss: 0.0174 - val_accuracy: 0.9962\n",
      "Epoch 34/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0066 - accuracy: 0.9994 - val_loss: 0.0174 - val_accuracy: 0.9949\n",
      "Epoch 35/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0078 - accuracy: 0.9994 - val_loss: 0.0189 - val_accuracy: 0.9937\n",
      "Epoch 36/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0065 - accuracy: 0.9993 - val_loss: 0.0165 - val_accuracy: 0.9958\n",
      "Epoch 37/100\n",
      "223/223 [==============================] - 55s 244ms/step - loss: 0.0060 - accuracy: 0.9993 - val_loss: 0.0190 - val_accuracy: 0.9945\n",
      "Epoch 38/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0050 - accuracy: 0.9996 - val_loss: 0.0165 - val_accuracy: 0.9949\n",
      "Epoch 39/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0044 - accuracy: 0.9997 - val_loss: 0.0177 - val_accuracy: 0.9958\n",
      "Epoch 40/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0040 - accuracy: 0.9997 - val_loss: 0.0158 - val_accuracy: 0.9958\n",
      "Epoch 41/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0044 - accuracy: 0.9999 - val_loss: 0.0168 - val_accuracy: 0.9941\n",
      "Epoch 42/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.0048 - accuracy: 0.9996 - val_loss: 0.0155 - val_accuracy: 0.9954\n",
      "Epoch 43/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0041 - accuracy: 0.9996 - val_loss: 0.0195 - val_accuracy: 0.9945\n",
      "Epoch 44/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0045 - accuracy: 0.9997 - val_loss: 0.0151 - val_accuracy: 0.9962\n",
      "Epoch 45/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0033 - accuracy: 0.9997 - val_loss: 0.0158 - val_accuracy: 0.9954\n",
      "Epoch 46/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.0153 - val_accuracy: 0.9954\n",
      "Epoch 47/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0031 - accuracy: 0.9999 - val_loss: 0.0141 - val_accuracy: 0.9958\n",
      "Epoch 48/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 0.0153 - val_accuracy: 0.9962\n",
      "Epoch 49/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.0152 - val_accuracy: 0.9966\n",
      "Epoch 50/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9954\n",
      "Epoch 51/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0038 - accuracy: 0.9999 - val_loss: 0.0165 - val_accuracy: 0.9958\n",
      "Epoch 52/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0029 - accuracy: 0.9999 - val_loss: 0.0274 - val_accuracy: 0.9903\n",
      "Epoch 53/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.0173 - val_accuracy: 0.9954\n",
      "Epoch 54/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0178 - val_accuracy: 0.9920\n",
      "Epoch 55/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0034 - accuracy: 0.9996 - val_loss: 0.0155 - val_accuracy: 0.9958\n",
      "Epoch 56/100\n",
      "223/223 [==============================] - 56s 250ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.0175 - val_accuracy: 0.9958\n",
      "Epoch 57/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 0.9949\n",
      "Epoch 58/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9954\n",
      "Epoch 59/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.0156 - val_accuracy: 0.9966\n",
      "Epoch 60/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.0167 - val_accuracy: 0.9958\n",
      "Epoch 61/100\n",
      "223/223 [==============================] - 55s 248ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.0175 - val_accuracy: 0.9949\n",
      "Epoch 62/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0143 - val_accuracy: 0.9958\n",
      "Epoch 63/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9971\n",
      "Epoch 64/100\n",
      "223/223 [==============================] - 53s 236ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9962\n",
      "Epoch 65/100\n",
      "223/223 [==============================] - 52s 235ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9954\n",
      "Epoch 66/100\n",
      "223/223 [==============================] - 53s 236ms/step - loss: 9.7211e-04 - accuracy: 0.9999 - val_loss: 0.0141 - val_accuracy: 0.9962\n",
      "Epoch 67/100\n",
      "223/223 [==============================] - 52s 235ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0162 - val_accuracy: 0.9958\n",
      "Epoch 68/100\n",
      "223/223 [==============================] - 52s 234ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.0157 - val_accuracy: 0.9954\n",
      "Epoch 69/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0186 - val_accuracy: 0.9949\n",
      "Epoch 70/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 0.9962\n",
      "Epoch 71/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.0145 - val_accuracy: 0.9971\n",
      "Epoch 72/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 9.1192e-04 - accuracy: 1.0000 - val_loss: 0.0180 - val_accuracy: 0.9945\n",
      "Epoch 73/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0179 - val_accuracy: 0.9949\n",
      "Epoch 74/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0162 - val_accuracy: 0.9949\n",
      "Epoch 75/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 9.6791e-04 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 0.9962\n",
      "Epoch 76/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 6.4152e-04 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 0.9966\n",
      "Epoch 77/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9966\n",
      "Epoch 78/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.0182 - val_accuracy: 0.9933\n",
      "Epoch 79/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0148 - val_accuracy: 0.9966\n",
      "Epoch 80/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 6.1295e-04 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9958\n",
      "Epoch 81/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 4.3365e-04 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9966\n",
      "Epoch 82/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 4.3624e-04 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9966\n",
      "Epoch 83/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 6.5439e-04 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 0.9958\n",
      "Epoch 84/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 7.0718e-04 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9958\n",
      "Epoch 85/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 8.1266e-04 - accuracy: 0.9999 - val_loss: 0.0149 - val_accuracy: 0.9966\n",
      "Epoch 86/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0124 - val_accuracy: 0.9966\n",
      "Epoch 87/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0128 - val_accuracy: 0.9971\n",
      "Epoch 88/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 5.1419e-04 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9966\n",
      "Epoch 89/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 4.4622e-04 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9971\n",
      "Epoch 90/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 6.4227e-04 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9966\n",
      "Epoch 91/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.0132 - val_accuracy: 0.9966\n",
      "Epoch 92/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0142 - val_accuracy: 0.9966\n",
      "Epoch 93/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 3.6467e-04 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9962\n",
      "Epoch 94/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 3.5090e-04 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9958\n",
      "Epoch 95/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 2.6056e-04 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9966\n",
      "Epoch 96/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 6.7672e-04 - accuracy: 0.9999 - val_loss: 0.0146 - val_accuracy: 0.9962\n",
      "Epoch 97/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 3.8879e-04 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9962\n",
      "Epoch 98/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 3.8750e-04 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9962\n",
      "Epoch 99/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0155 - val_accuracy: 0.9945\n",
      "Epoch 100/100\n",
      "223/223 [==============================] - 52s 233ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0122 - val_accuracy: 0.9966\n"
     ]
    }
   ],
   "source": [
    "history_7, model_7 = fit_model(build_7, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"100_Dense_0-DO_0.4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 299, 299, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 149, 149, 32  864         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 149, 149, 32  96         ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 149, 149, 32  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 147, 147, 32  9216        ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 147, 147, 32  96         ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 147, 147, 32  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 147, 147, 64  18432       ['activation_1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 147, 147, 64  192        ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 147, 147, 64  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 73, 73, 64)   0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 73, 73, 80)   5120        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 73, 73, 80)  240         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 73, 73, 80)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 71, 71, 192)  138240      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 71, 71, 192)  576        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 71, 71, 192)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0          ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 35, 35, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 35, 35, 96)   55296       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 35, 35, 48)  144         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 35, 35, 96)  288         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 35, 35, 48)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 35, 35, 96)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 35, 35, 192)  0          ['max_pooling2d_1[0][0]']        \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 35, 35, 64)   76800       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 35, 35, 32)   6144        ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 35, 35, 96)  288         ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 35, 35, 32)  96          ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 35, 35, 256)  0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_7[0][0]',           \n",
      "                                                                  'activation_10[0][0]',          \n",
      "                                                                  'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 35, 35, 64)  192         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 35, 35, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 35, 35, 48)  144         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 35, 35, 96)  288         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 35, 35, 256)  0          ['mixed0[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 35, 35, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 35, 35, 64)  192         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 35, 35, 64)  192         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 35, 35, 96)  288         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 35, 35, 64)  192         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 35, 35, 288)  0           ['activation_12[0][0]',          \n",
      "                                                                  'activation_14[0][0]',          \n",
      "                                                                  'activation_17[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 35, 35, 64)  192         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 35, 35, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 35, 35, 48)  144         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 35, 35, 96)  288         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 35, 35, 288)  0          ['mixed1[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 35, 35, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 35, 35, 64)  192         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 35, 35, 64)  192         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 35, 35, 96)  288         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 35, 35, 64)  192         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 35, 35, 288)  0           ['activation_19[0][0]',          \n",
      "                                                                  'activation_21[0][0]',          \n",
      "                                                                  'activation_24[0][0]',          \n",
      "                                                                  'activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 35, 35, 64)  192         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 35, 35, 96)  288         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 17, 17, 384)  995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 17, 17, 96)   82944       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 17, 17, 384)  1152       ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 17, 17, 96)  288         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 17, 17, 384)  0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 17, 17, 96)   0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0          ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 17, 17, 768)  0           ['activation_26[0][0]',          \n",
      "                                                                  'activation_29[0][0]',          \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 17, 17, 128)  384        ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 17, 17, 128)  384        ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 17, 17, 128)  384        ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 17, 17, 128)  384        ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 17, 17, 128)  384        ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 17, 17, 128)  384        ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 17, 17, 768)  0          ['mixed3[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 17, 17, 192)  576        ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 17, 17, 192)  576        ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 17, 17, 192)  576        ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 17, 17, 192)  576        ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 17, 17, 768)  0           ['activation_30[0][0]',          \n",
      "                                                                  'activation_33[0][0]',          \n",
      "                                                                  'activation_38[0][0]',          \n",
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 17, 17, 160)  480        ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 17, 17, 160)  480        ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 17, 17, 160)  480        ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 17, 17, 160)  480        ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 17, 17, 160)  480        ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 17, 17, 160)  480        ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, 17, 17, 768)  0          ['mixed4[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 17, 17, 192)  576        ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 17, 17, 192)  576        ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 17, 17, 192)  576        ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 17, 17, 192)  576        ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 17, 17, 768)  0           ['activation_40[0][0]',          \n",
      "                                                                  'activation_43[0][0]',          \n",
      "                                                                  'activation_48[0][0]',          \n",
      "                                                                  'activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 17, 17, 160)  480        ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 17, 17, 160)  480        ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 17, 17, 160)  480        ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 17, 17, 160)  480        ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 17, 17, 160)  480        ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 17, 17, 160)  480        ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, 17, 17, 768)  0          ['mixed5[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_5[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 17, 17, 192)  576        ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 17, 17, 192)  576        ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 17, 17, 192)  576        ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 17, 17, 192)  576        ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 17, 17, 768)  0           ['activation_50[0][0]',          \n",
      "                                                                  'activation_53[0][0]',          \n",
      "                                                                  'activation_58[0][0]',          \n",
      "                                                                  'activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 17, 17, 192)  576        ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 17, 17, 192)  576        ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 17, 17, 192)  576        ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 17, 17, 192)  576        ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 17, 17, 192)  576        ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 17, 17, 192)  576        ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (AveragePo  (None, 17, 17, 768)  0          ['mixed6[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_6[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 17, 17, 192)  576        ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 17, 17, 192)  576        ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 17, 17, 192)  576        ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 17, 17, 192)  576        ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 17, 17, 768)  0           ['activation_60[0][0]',          \n",
      "                                                                  'activation_63[0][0]',          \n",
      "                                                                  'activation_68[0][0]',          \n",
      "                                                                  'activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 17, 17, 192)  576        ['conv2d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_72[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 17, 17, 192)  576        ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_73[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 17, 17, 192)  576        ['conv2d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 17, 17, 192)  576        ['conv2d_74[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 8, 8, 320)    552960      ['activation_70[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 8, 8, 192)    331776      ['activation_74[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 8, 8, 320)   960         ['conv2d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 8, 8, 192)   576         ['conv2d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)   0           ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 8, 8, 1280)   0           ['activation_71[0][0]',          \n",
      "                                                                  'activation_75[0][0]',          \n",
      "                                                                  'max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 8, 8, 448)    573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_80[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 8, 8, 384)    491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_80[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_7 (AveragePo  (None, 8, 8, 1280)  0           ['mixed8[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 8, 8, 320)    409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_78[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_79[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_82[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_83[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 8, 8, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 8, 8, 320)   960         ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 8, 8, 192)   576         ['conv2d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 8, 8, 768)    0           ['activation_78[0][0]',          \n",
      "                                                                  'activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 8, 8, 768)    0           ['activation_82[0][0]',          \n",
      "                                                                  'activation_83[0][0]']          \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, 8, 8, 2048)   0           ['activation_76[0][0]',          \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate[0][0]',            \n",
      "                                                                  'activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 8, 8, 448)    917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 8, 8, 384)    786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_89[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_86[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_8 (AveragePo  (None, 8, 8, 2048)  0           ['mixed9[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 8, 8, 320)    655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_88[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_91[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_92[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 8, 8, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 8, 8, 320)   960         ['conv2d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 8, 8, 192)   576         ['conv2d_93[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 8, 8, 768)    0           ['activation_87[0][0]',          \n",
      "                                                                  'activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 8, 8, 768)    0           ['activation_91[0][0]',          \n",
      "                                                                  'activation_92[0][0]']          \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 8, 8, 2048)   0           ['activation_85[0][0]',          \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_1[0][0]',          \n",
      "                                                                  'activation_93[0][0]']          \n",
      "                                                                                                  \n",
      " global_average_pooling2d_10 (G  (None, 2048)        0           ['mixed10[0][0]']                \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 2048)         0           ['global_average_pooling2d_10[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 4)            8196        ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,810,980\n",
      "Trainable params: 8,196\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "build_8 = build_model(0, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "223/223 [==============================] - 87s 368ms/step - loss: 1.1401 - accuracy: 0.5001 - val_loss: 0.7296 - val_accuracy: 0.7585\n",
      "Epoch 2/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.7153 - accuracy: 0.7246 - val_loss: 0.5394 - val_accuracy: 0.8150\n",
      "Epoch 3/100\n",
      "223/223 [==============================] - 54s 243ms/step - loss: 0.5738 - accuracy: 0.7901 - val_loss: 0.4448 - val_accuracy: 0.8550\n",
      "Epoch 4/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.4938 - accuracy: 0.8167 - val_loss: 0.3835 - val_accuracy: 0.8757\n",
      "Epoch 5/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.4332 - accuracy: 0.8459 - val_loss: 0.3412 - val_accuracy: 0.8925\n",
      "Epoch 6/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.3950 - accuracy: 0.8622 - val_loss: 0.3100 - val_accuracy: 0.9014\n",
      "Epoch 7/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.3641 - accuracy: 0.8743 - val_loss: 0.2862 - val_accuracy: 0.9123\n",
      "Epoch 8/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.3349 - accuracy: 0.8858 - val_loss: 0.2690 - val_accuracy: 0.9170\n",
      "Epoch 9/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.3159 - accuracy: 0.8907 - val_loss: 0.2477 - val_accuracy: 0.9258\n",
      "Epoch 10/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.2907 - accuracy: 0.9018 - val_loss: 0.2348 - val_accuracy: 0.9351\n",
      "Epoch 11/100\n",
      "223/223 [==============================] - 55s 244ms/step - loss: 0.2817 - accuracy: 0.9047 - val_loss: 0.2217 - val_accuracy: 0.9389\n",
      "Epoch 12/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.2697 - accuracy: 0.9091 - val_loss: 0.2103 - val_accuracy: 0.9440\n",
      "Epoch 13/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.2571 - accuracy: 0.9167 - val_loss: 0.2029 - val_accuracy: 0.9431\n",
      "Epoch 14/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.2508 - accuracy: 0.9153 - val_loss: 0.1939 - val_accuracy: 0.9469\n",
      "Epoch 15/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.2393 - accuracy: 0.9202 - val_loss: 0.1842 - val_accuracy: 0.9515\n",
      "Epoch 16/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.2258 - accuracy: 0.9253 - val_loss: 0.1781 - val_accuracy: 0.9528\n",
      "Epoch 17/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.2190 - accuracy: 0.9237 - val_loss: 0.1700 - val_accuracy: 0.9558\n",
      "Epoch 18/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.2097 - accuracy: 0.9300 - val_loss: 0.1638 - val_accuracy: 0.9579\n",
      "Epoch 19/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.2047 - accuracy: 0.9291 - val_loss: 0.1583 - val_accuracy: 0.9604\n",
      "Epoch 20/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.2011 - accuracy: 0.9350 - val_loss: 0.1541 - val_accuracy: 0.9600\n",
      "Epoch 21/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.1926 - accuracy: 0.9355 - val_loss: 0.1489 - val_accuracy: 0.9638\n",
      "Epoch 22/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.1932 - accuracy: 0.9351 - val_loss: 0.1448 - val_accuracy: 0.9633\n",
      "Epoch 23/100\n",
      "223/223 [==============================] - 55s 247ms/step - loss: 0.1866 - accuracy: 0.9414 - val_loss: 0.1409 - val_accuracy: 0.9684\n",
      "Epoch 24/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.1839 - accuracy: 0.9373 - val_loss: 0.1372 - val_accuracy: 0.9676\n",
      "Epoch 25/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.1782 - accuracy: 0.9414 - val_loss: 0.1336 - val_accuracy: 0.9726\n",
      "Epoch 26/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.1719 - accuracy: 0.9459 - val_loss: 0.1307 - val_accuracy: 0.9701\n",
      "Epoch 27/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.1669 - accuracy: 0.9453 - val_loss: 0.1275 - val_accuracy: 0.9722\n",
      "Epoch 28/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.1682 - accuracy: 0.9445 - val_loss: 0.1251 - val_accuracy: 0.9692\n",
      "Epoch 29/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.1673 - accuracy: 0.9466 - val_loss: 0.1221 - val_accuracy: 0.9688\n",
      "Epoch 30/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.1645 - accuracy: 0.9456 - val_loss: 0.1188 - val_accuracy: 0.9722\n",
      "Epoch 31/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1581 - accuracy: 0.9501 - val_loss: 0.1163 - val_accuracy: 0.9764\n",
      "Epoch 32/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1563 - accuracy: 0.9493 - val_loss: 0.1143 - val_accuracy: 0.9739\n",
      "Epoch 33/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.1524 - accuracy: 0.9517 - val_loss: 0.1118 - val_accuracy: 0.9735\n",
      "Epoch 34/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.1463 - accuracy: 0.9543 - val_loss: 0.1103 - val_accuracy: 0.9764\n",
      "Epoch 35/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1497 - accuracy: 0.9534 - val_loss: 0.1083 - val_accuracy: 0.9747\n",
      "Epoch 36/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1516 - accuracy: 0.9513 - val_loss: 0.1065 - val_accuracy: 0.9760\n",
      "Epoch 37/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1427 - accuracy: 0.9536 - val_loss: 0.1041 - val_accuracy: 0.9760\n",
      "Epoch 38/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1434 - accuracy: 0.9539 - val_loss: 0.1021 - val_accuracy: 0.9772\n",
      "Epoch 39/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.1399 - accuracy: 0.9562 - val_loss: 0.1011 - val_accuracy: 0.9781\n",
      "Epoch 40/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1443 - accuracy: 0.9517 - val_loss: 0.1006 - val_accuracy: 0.9756\n",
      "Epoch 41/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1378 - accuracy: 0.9564 - val_loss: 0.0992 - val_accuracy: 0.9751\n",
      "Epoch 42/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1336 - accuracy: 0.9563 - val_loss: 0.0965 - val_accuracy: 0.9781\n",
      "Epoch 43/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1372 - accuracy: 0.9559 - val_loss: 0.0971 - val_accuracy: 0.9768\n",
      "Epoch 44/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1328 - accuracy: 0.9548 - val_loss: 0.0937 - val_accuracy: 0.9798\n",
      "Epoch 45/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1336 - accuracy: 0.9553 - val_loss: 0.0925 - val_accuracy: 0.9794\n",
      "Epoch 46/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1311 - accuracy: 0.9572 - val_loss: 0.0922 - val_accuracy: 0.9785\n",
      "Epoch 47/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1321 - accuracy: 0.9559 - val_loss: 0.0909 - val_accuracy: 0.9794\n",
      "Epoch 48/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1271 - accuracy: 0.9559 - val_loss: 0.0890 - val_accuracy: 0.9806\n",
      "Epoch 49/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1251 - accuracy: 0.9579 - val_loss: 0.0882 - val_accuracy: 0.9789\n",
      "Epoch 50/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.1302 - accuracy: 0.9573 - val_loss: 0.0871 - val_accuracy: 0.9806\n",
      "Epoch 51/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.1271 - accuracy: 0.9563 - val_loss: 0.0867 - val_accuracy: 0.9789\n",
      "Epoch 52/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1272 - accuracy: 0.9583 - val_loss: 0.0861 - val_accuracy: 0.9794\n",
      "Epoch 53/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1246 - accuracy: 0.9600 - val_loss: 0.0850 - val_accuracy: 0.9794\n",
      "Epoch 54/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.1217 - accuracy: 0.9600 - val_loss: 0.0837 - val_accuracy: 0.9823\n",
      "Epoch 55/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1244 - accuracy: 0.9587 - val_loss: 0.0839 - val_accuracy: 0.9806\n",
      "Epoch 56/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1229 - accuracy: 0.9579 - val_loss: 0.0826 - val_accuracy: 0.9815\n",
      "Epoch 57/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1239 - accuracy: 0.9601 - val_loss: 0.0818 - val_accuracy: 0.9806\n",
      "Epoch 58/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1239 - accuracy: 0.9601 - val_loss: 0.0803 - val_accuracy: 0.9827\n",
      "Epoch 59/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.1233 - accuracy: 0.9591 - val_loss: 0.0788 - val_accuracy: 0.9827\n",
      "Epoch 60/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1194 - accuracy: 0.9580 - val_loss: 0.0784 - val_accuracy: 0.9815\n",
      "Epoch 61/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1192 - accuracy: 0.9586 - val_loss: 0.0772 - val_accuracy: 0.9827\n",
      "Epoch 62/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1134 - accuracy: 0.9625 - val_loss: 0.0769 - val_accuracy: 0.9827\n",
      "Epoch 63/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1146 - accuracy: 0.9609 - val_loss: 0.0763 - val_accuracy: 0.9815\n",
      "Epoch 64/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1124 - accuracy: 0.9622 - val_loss: 0.0770 - val_accuracy: 0.9819\n",
      "Epoch 65/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.1140 - accuracy: 0.9609 - val_loss: 0.0750 - val_accuracy: 0.9823\n",
      "Epoch 66/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1086 - accuracy: 0.9650 - val_loss: 0.0741 - val_accuracy: 0.9831\n",
      "Epoch 67/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1121 - accuracy: 0.9632 - val_loss: 0.0764 - val_accuracy: 0.9831\n",
      "Epoch 68/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1128 - accuracy: 0.9632 - val_loss: 0.0730 - val_accuracy: 0.9840\n",
      "Epoch 69/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1135 - accuracy: 0.9614 - val_loss: 0.0720 - val_accuracy: 0.9836\n",
      "Epoch 70/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1077 - accuracy: 0.9661 - val_loss: 0.0714 - val_accuracy: 0.9836\n",
      "Epoch 71/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1141 - accuracy: 0.9614 - val_loss: 0.0713 - val_accuracy: 0.9844\n",
      "Epoch 72/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1102 - accuracy: 0.9626 - val_loss: 0.0703 - val_accuracy: 0.9836\n",
      "Epoch 73/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1093 - accuracy: 0.9628 - val_loss: 0.0738 - val_accuracy: 0.9806\n",
      "Epoch 74/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1100 - accuracy: 0.9618 - val_loss: 0.0705 - val_accuracy: 0.9844\n",
      "Epoch 75/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.1079 - accuracy: 0.9646 - val_loss: 0.0688 - val_accuracy: 0.9831\n",
      "Epoch 76/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.1092 - accuracy: 0.9654 - val_loss: 0.0681 - val_accuracy: 0.9844\n",
      "Epoch 77/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1105 - accuracy: 0.9632 - val_loss: 0.0676 - val_accuracy: 0.9844\n",
      "Epoch 78/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1042 - accuracy: 0.9653 - val_loss: 0.0674 - val_accuracy: 0.9840\n",
      "Epoch 79/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1117 - accuracy: 0.9616 - val_loss: 0.0675 - val_accuracy: 0.9840\n",
      "Epoch 80/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1038 - accuracy: 0.9659 - val_loss: 0.0667 - val_accuracy: 0.9861\n",
      "Epoch 81/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1090 - accuracy: 0.9619 - val_loss: 0.0659 - val_accuracy: 0.9840\n",
      "Epoch 82/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.1068 - accuracy: 0.9653 - val_loss: 0.0653 - val_accuracy: 0.9853\n",
      "Epoch 83/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1094 - accuracy: 0.9646 - val_loss: 0.0657 - val_accuracy: 0.9844\n",
      "Epoch 84/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1033 - accuracy: 0.9674 - val_loss: 0.0644 - val_accuracy: 0.9848\n",
      "Epoch 85/100\n",
      "223/223 [==============================] - 55s 246ms/step - loss: 0.1078 - accuracy: 0.9649 - val_loss: 0.0643 - val_accuracy: 0.9853\n",
      "Epoch 86/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1076 - accuracy: 0.9649 - val_loss: 0.0638 - val_accuracy: 0.9857\n",
      "Epoch 87/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0985 - accuracy: 0.9685 - val_loss: 0.0636 - val_accuracy: 0.9844\n",
      "Epoch 88/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1085 - accuracy: 0.9626 - val_loss: 0.0638 - val_accuracy: 0.9853\n",
      "Epoch 89/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1054 - accuracy: 0.9660 - val_loss: 0.0633 - val_accuracy: 0.9857\n",
      "Epoch 90/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1011 - accuracy: 0.9663 - val_loss: 0.0625 - val_accuracy: 0.9853\n",
      "Epoch 91/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1028 - accuracy: 0.9631 - val_loss: 0.0623 - val_accuracy: 0.9853\n",
      "Epoch 92/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0992 - accuracy: 0.9675 - val_loss: 0.0622 - val_accuracy: 0.9861\n",
      "Epoch 93/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1050 - accuracy: 0.9643 - val_loss: 0.0611 - val_accuracy: 0.9865\n",
      "Epoch 94/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1006 - accuracy: 0.9666 - val_loss: 0.0613 - val_accuracy: 0.9861\n",
      "Epoch 95/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0969 - accuracy: 0.9698 - val_loss: 0.0612 - val_accuracy: 0.9857\n",
      "Epoch 96/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.1010 - accuracy: 0.9653 - val_loss: 0.0619 - val_accuracy: 0.9844\n",
      "Epoch 97/100\n",
      "223/223 [==============================] - 55s 245ms/step - loss: 0.0990 - accuracy: 0.9684 - val_loss: 0.0611 - val_accuracy: 0.9848\n",
      "Epoch 98/100\n",
      "223/223 [==============================] - 54s 244ms/step - loss: 0.0988 - accuracy: 0.9674 - val_loss: 0.0600 - val_accuracy: 0.9865\n",
      "Epoch 99/100\n",
      "223/223 [==============================] - 67s 300ms/step - loss: 0.1024 - accuracy: 0.9654 - val_loss: 0.0594 - val_accuracy: 0.9857\n",
      "Epoch 100/100\n",
      "223/223 [==============================] - 58s 261ms/step - loss: 0.0980 - accuracy: 0.9677 - val_loss: 0.0616 - val_accuracy: 0.9844\n"
     ]
    }
   ],
   "source": [
    "history_8, model_8 = fit_model(build_8, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluation(model, plot=True, report = True, save=True):\n",
    "  title = model.name\n",
    "  heading = f'\\n<==== {title} ====>'\n",
    "  print(heading)\n",
    "  \n",
    "  predictions = model.predict(test_generator)\n",
    "  y_true = test_generator.classes\n",
    "  y_pred_classes = np.argmax(predictions, axis=1)\n",
    "  \n",
    "  if plot:\n",
    "    conf_matrix = confusion_matrix(y_pred_classes, y_true)\n",
    "    mat = plt\n",
    "    mat.figure(figsize=(7, 5))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "                xticklabels=test_generator.class_indices.keys(),\n",
    "                yticklabels=test_generator.class_indices.keys())\n",
    "    mat.ylabel('Actual')\n",
    "    mat.xlabel('Predicted')\n",
    "    mat.suptitle(title, fontsize=11)    \n",
    "    mat.savefig('report/confusion_matrix/'+title.replace(\".\", \",\")+'_matrix.png')\n",
    "    mat.show()\n",
    "    \n",
    "  if report:\n",
    "    test_loss, test_acc = model.evaluate(test_generator)\n",
    "    acc_loss = f'Test accuracy: {round(test_acc*100,2)}%, test loss: {round(test_loss*100,2)}%'\n",
    "    print(acc_loss)\n",
    "    \n",
    "    target_names = list(test_generator.class_indices.keys())\n",
    "    clas_report = classification_report(y_true, y_pred_classes, target_names=target_names)\n",
    "    print(clas_report)\n",
    " \n",
    "  if save:\n",
    "    dis = plt\n",
    "    fig, ax = dis.subplots(figsize=(8, 4))\n",
    "    \n",
    "    ax.text(0.1, 1, f\"<==== {title} ====>\", fontsize=11, ha='left')\n",
    "    ax.text(0.1, 0.85, acc_loss, fontsize=10, ha='left')\n",
    "    ax.text(0.1, 0.15, \"Classification Report: \\n\" + clas_report, fontsize=10, ha='left', family='monospace')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    dis.savefig(f\"report/classification_reports/{title}.png\")\n",
    "    dis.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_graph(history, title, save = True):\n",
    "  fig , ax = plt.subplots(1,2)\n",
    "  train_acc = history['accuracy']\n",
    "  train_loss = history['loss']\n",
    "  val_acc = history['val_accuracy']\n",
    "  val_loss = history['val_loss']\n",
    "  fig.set_size_inches(9,3)\n",
    "\n",
    "  ax[0].plot(train_acc)\n",
    "  ax[0].plot(val_acc)\n",
    "  ax[0].set_title('Training Accuracy vs Validation Accuracy')\n",
    "  ax[0].set_ylabel('Accuracy')\n",
    "  ax[0].set_xlabel('Epoch')\n",
    "  ax[0].legend(['Train', 'Validation'],)\n",
    "\n",
    "  ax[1].plot(train_loss)\n",
    "  ax[1].plot(val_loss)\n",
    "  ax[1].set_title('Training Loss vs Validation Loss')\n",
    "  ax[1].set_ylabel('Loss')\n",
    "  ax[1].set_xlabel('Epoch')\n",
    "  ax[1].legend(['Train', 'Validation'])\n",
    "\n",
    "  # Add a title for the entire figure\n",
    "  fig.suptitle(title, fontsize=11)\n",
    "  plt.subplots_adjust(top=0.85)\n",
    "  if save:\n",
    "    plt.savefig('report/train_graph/'+title.replace(\".\", \",\")+'_graph')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model):  \n",
    "  filename = f'model/epoch/{model.name}.keras'\n",
    "  model.save(filename)\n",
    "\n",
    "import pickle\n",
    "\n",
    "def save_history(name, history):\n",
    "  with open(f'model/history/{name}_history.pkl', 'wb') as file:\n",
    "    pickle.dump(history.history, file)\n",
    "    \n",
    "def load_history(name):\n",
    "  with open(name, 'rb') as file:\n",
    "      return pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<==== 100_Dense_0-DO_0.4 ====>\n",
      "75/75 [==============================] - 24s 284ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 14s 182ms/step - loss: 0.0711 - accuracy: 0.9810\n",
      "Test accuracy: 98.1%, test loss: 7.11%\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Bacterial Blight       0.98      0.99      0.98       634\n",
      "           Blast       0.98      0.96      0.97       576\n",
      "      Brown Spot       0.98      0.98      0.98       640\n",
      "          Tungro       1.00      1.00      1.00       523\n",
      "\n",
      "        accuracy                           0.98      2373\n",
      "       macro avg       0.98      0.98      0.98      2373\n",
      "    weighted avg       0.98      0.98      0.98      2373\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model = load_model('model/dense/Dense_228-DO_2.3.h5')\n",
    "# his =  load_history('model/history/Dense_228-DO_2.5_history.pkl')\n",
    "# for i in [2,2,2]:\n",
    "# his = [history_4, history_5, history_6, history_7]\n",
    "# mod = [model_4, model_5, model_6, model_7]\n",
    "# for i in range(len(mod)):\n",
    "  # print(model_8.name)\n",
    "  # print(his[i])\n",
    "  \n",
    "evaluation(model_8)\n",
    "save_model(model_8)\n",
    "train_graph(history_8.history, model_8.name)\n",
    "save_history(model_8.name, history_8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'model/(11-06_11-54)99.494.h5'\n",
    "this_model = load_model(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = {0: 'Bacterial Blight', 1: 'Blast', 2: 'Brown Spot', 3: 'Tungro'}\n",
    "height = 299\n",
    "width = 299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_array(img_path):\n",
    "  img = image.load_img(img_path, target_size=(height, width))\n",
    "  img_array = image.img_to_array(img)\n",
    "  img_array = np.expand_dims(img_array, axis=0)\n",
    "  img_array = preprocess_input(img_array)\n",
    "  return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(img_path, this_model, class_names):\n",
    "    img_array = img_to_array(img_path)\n",
    "   \n",
    "    predictions = this_model.predict(img_array, verbose=1)\n",
    "    predicted_index = np.argmax(predictions)\n",
    "\n",
    "    confidence_score = round(predictions[0][predicted_index] * 100, 3)\n",
    "\n",
    "    predicted_class = class_names[predicted_index]\n",
    "    return predicted_class, confidence_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'dataset/Tungro/TUNGRO1_003.jpg'\n",
    "\n",
    "predicted_class, confidence_score = get_prediction(img_path, this_model, class_names)\n",
    "print(f'Predicted class: {predicted_class} with confidence score: {confidence_score} %')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fungsi mendapatkan heatmap gradcam\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    \n",
    "    # variabel grad_model digunakan untuk\n",
    "    grad_model = Model(\n",
    "        model.inputs, [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "    \n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    \n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    heatmap = heatmap.numpy()\n",
    "    \n",
    "    return heatmap, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_heatmap(img_path, this_model, pred_id=None, show=False):\n",
    "  last_conv_layer_name = \"mixed10\"\n",
    "\n",
    "  this_model.layers[-1].activation = None\n",
    "  \n",
    "  img_arr = img_to_array(img_path)\n",
    "  heatmap, preds = make_gradcam_heatmap(img_arr, this_model, last_conv_layer_name, pred_id)\n",
    "\n",
    "  pred_idx = np.argmax(preds[0])\n",
    "  confidence_level = tf.reduce_max(tf.nn.softmax(preds[0])).numpy()\n",
    "  score = round(confidence_level * 100, 3)\n",
    "  \n",
    "  label = f\"{class_names[pred_idx]}, {score}%\"\n",
    "  if show:\n",
    "    plt.matshow(heatmap)\n",
    "    plt.show()\n",
    "  return heatmap, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as PilImage, ImageDraw, ImageFont\n",
    "import matplotlib as mpl \n",
    "\n",
    "def save_and_display_gradcam(img_path, heatmap, max_width=None, cam_path=\"result\", alpha=0.5, label=None, show=True):\n",
    "    img = keras.utils.load_img(img_path)\n",
    "    img = keras.utils.img_to_array(img)\n",
    "\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    jet = mpl.colormaps[\"jet\"]\n",
    "\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    jet_heatmap = keras.utils.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = keras.utils.img_to_array(jet_heatmap)\n",
    "\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = keras.utils.array_to_img(superimposed_img)\n",
    "\n",
    "    superimposed_img.save(cam_path+'.jpg')\n",
    "\n",
    "    if label != None:\n",
    "        image_with_text = PilImage.open(cam_path+'.jpg')\n",
    "        fs = image_with_text.width//18\n",
    "        draw = ImageDraw.Draw(image_with_text)\n",
    "        font = ImageFont.truetype(\"arial.ttf\", fs)\n",
    "        text_size = draw.textbbox((0, 0), label, font=font)\n",
    "        text_position = (0,0)\n",
    "        draw.rectangle((text_position[0], text_position[1], text_position[0] + text_size[2], text_position[1] + text_size[3]), fill=\"black\")\n",
    "        draw.text(text_position, label, fill=\"white\", font=font)\n",
    "        image_with_text.save(cam_path+'.jpg')\n",
    "    if show:\n",
    "        display(Image(filename=cam_path+'.jpg', width=max_width))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict and show GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ['dataset/Bacterial Blight/BACTERAILBLIGHT3_024.jpg','dataset/Bacterial Blight/BACTERIALBLIGHT2_204.JPG','dataset/Bacterial Blight/BACTERIALBLIGHT2_192.jpg','dataset/Blast/BLAST9_139.JPG','dataset/Blast/BLAST1_002.jpg','dataset/Blast/BLAST9_107.jpg','dataset/Brown Spot/brownspot_orig_028.jpg','dataset/Brown Spot/BROWNSPOT7_195.jpg','dataset/Tungro/TUNGRO1_008.jpg','dataset/Tungro/TUNGRO5_193.JPG', 'dataset/Tungro/TUNGRO5_113.jpg','dataset/Tungro/TUNGRO1_028.jpg','dataset/Bacterial Blight/BACTERAILBLIGHT3_036.jpg','dataset/Bacterial Blight/BACTERAILBLIGHT3_043.jpg','dataset/Blast/BLAST1_030.jpg','dataset/Blast/BLAST9_154.jpg','dataset/Blast/BLAST9_157.jpg','dataset/Brown Spot/brownspot_orig_040.jpg','dataset/Brown Spot/BROWNSPOT7_040.jpg','dataset/Tungro/TUNGRO1_004.jpg','dataset/Tungro/TUNGRO5_191.JPG','dataset/Tungro/TUNGRO4_138.JPG']\n",
    "d12803 = load_model('model/dense/100_Dense_128-DO_0.3.keras')\n",
    "# print(f'...{model.name}')\n",
    "import random as rd\n",
    "for c in img:\n",
    "  num = rd.randint(1,120)\n",
    "  name = os.path.basename(os.path.dirname(c))\n",
    "  \n",
    "  heatmap, label = get_heatmap(c, d12803)\n",
    "  save_and_display_gradcam(c, heatmap, 300, alpha=0.7, cam_path=f'gradcam/{name}/{num}', show=False)\n",
    "\n",
    "# heatmap, label = get_heatmap('dataset/Bacterial Blight/BACTERAILBLIGHT3_003.jpg', model_0)\n",
    "# save_and_display_gradcam('dataset/Bacterial Blight/BACTERAILBLIGHT3_003.jpg', heatmap, 300, alpha=0.7)\n",
    "# heatmap, label = get_heatmap('dataset/Bacterial Blight/BACTERAILBLIGHT3_003.jpg', model_1)\n",
    "# save_and_display_gradcam('dataset/Bacterial Blight/BACTERAILBLIGHT3_003.jpg', heatmap, 300, alpha=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19 images belonging to 4 classes.\n",
      "WARNING:tensorflow:6 out of the last 80 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001C34C8B2320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "WARNING:tensorflow:5 out of the last 25 calls to <function Model.make_test_function.<locals>.test_function at 0x000001C34C8B2EF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.6450 - accuracy: 0.5263\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Bacterial Blight       0.50      0.75      0.60         4\n",
      "           Blast       0.29      0.50      0.36         4\n",
      "      Brown Spot       1.00      0.43      0.60         7\n",
      "          Tungro       0.67      0.50      0.57         4\n",
      "\n",
      "        accuracy                           0.53        19\n",
      "       macro avg       0.61      0.54      0.53        19\n",
      "    weighted avg       0.67      0.53      0.54        19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_dir = 'img/test'\n",
    "check = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(height, width),\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# model = load_model('model/dense/Dense_128-DO_0.5.h5')\n",
    "# predictions = model.predict(check)\n",
    "# y_pred_classes = np.argmax(predictions, axis=1)\n",
    "# y_true = check.classes\n",
    "test_loss, test_acc = model.evaluate(check)\n",
    "# Print classification report\n",
    "target_names = list(test_generator.class_indices.keys())\n",
    "print(classification_report(y_true, y_pred_classes, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
